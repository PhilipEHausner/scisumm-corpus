Dynamic programming efficiently scores many hypotheses by exploiting the fact that an N-gram language model conditions on at most N & IRSTLM ( Federico et al. , 2008 ) is an open-source toolkit for building and querying language models . Nicola Bertoldi and Marcello Federico assisted with IRSTLM . Nicola Bertoldi and Marcello Federico assisted with IRSTLM . IRSTLM ( Federico et al. , 2008 ) is an open-source toolkit for building and querying language models . Time for Moses itself to load , including loading the language model and phrase table , is included . This paper presents methods to query N-gram language models , minimizing time and space costs . In addition to the optimizations specific to each datastructure described in Section 2 , we implement several general optimizations for language modeling . The trie data structure is commonly used for language modeling . For the perplexity and translation tasks , we used SRILM to build a 5-gram English language model on 834 million tokens from Europarl v6 ( Koehn , 2005 ) and the 2011 Workshop on Machine Translation News Crawl corpus with duplicate lines removed . Performance improvements transfer to the Moses ( Koehn et al. , 2007 ) , cdec ( Dyer et al. , 2010 ) , and Joshua ( Li et al. , 2009 ) translation systems where our code has been integrated .
