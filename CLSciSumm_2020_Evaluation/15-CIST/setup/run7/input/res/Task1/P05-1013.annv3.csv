Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P05-1013,W05-1505,0,"Nivre and Nilsson, 2005",0,"Recent work by Nivre and Nilsson introduces a technique where the projectivization transformation is encoded in the non-terminals of constituents during parsing (Nivre and Nilsson, 2005)","Recent work by Nivre and Nilsson introduces a technique where the projectivization transformation is encoded in the non-terminals of constituents during parsing (Nivre and Nilsson, 2005)","[20, 21, 61, 109]","['<S sid=""20"" ssid=""16"">In this paper, we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques.</S>', '<S sid=""21"" ssid=""17"">First, the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al., 1998) and encoding information about these lifts in arc labels.</S>', '<S sid=""61"" ssid=""32"">Before we turn to the evaluation, however, we need to introduce the data-driven dependency parser used in the latter experiments.</S>', '<S sid=""109"" ssid=""1"">We have presented a new method for non-projective dependency parsing, based on a combination of data-driven projective dependency parsing and graph transformation techniques.</S>']",Method_Citation
2,P05-1013,P08-1006,0,"Nivre and Nilsson, 2005",0,"1http: //sourceforge.net/projects/mstparser Figure 1: CoNLL-X dependency tree Figure 2: Penn Treebank-style phrase structure tree KSDEP Sagae and Tsujii (2007)? s dependencyparser,2 based on a probabilistic shift-reduce algorithm extended by the pseudo-projective parsing technique (Nivre and Nilsson, 2005)","Sagae and Tsujii (2007)'s dependency parser, based on a probabilistic shift-reduce algorithm extended by the pseudo-projective parsing technique (Nivre and Nilsson, 2005)","[9, 62, 65, 109]","['<S sid=""9"" ssid=""5"">This is true of the widely used link grammar parser for English (Sleator and Temperley, 1993), which uses a dependency grammar of sorts, the probabilistic dependency parser of Eisner (1996), and more recently proposed deterministic dependency parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004).</S>', '<S sid=""62"" ssid=""1"">In the experiments below, we employ a data-driven deterministic dependency parser producing labeled projective dependency graphs,3 previously tested on Swedish (Nivre et al., 2004) and English (Nivre and Scholz, 2004).</S>', '<S sid=""65"" ssid=""4"">More details on the parsing algorithm can be found in Nivre (2003).</S>', '<S sid=""109"" ssid=""1"">We have presented a new method for non-projective dependency parsing, based on a combination of data-driven projective dependency parsing and graph transformation techniques.</S>']","Results_Citation,Method_Citation"
3,P05-1013,W10-1401,0,"Nivre and Nilsson, 2005",0,"Bengoetxea and Gojenola (2010) discuss non-projective dependencies in Basque and show that the pseudo-projective transformation of (Nivre and Nilsson, 2005) improves accuracy for dependency parsing of Basque","Bengoetxea and Gojenola (2010) discuss non-projective dependencies in Basque and show that the pseudo-projective transformation of (Nivre and Nilsson, 2005) improves accuracy for dependency parsing of Basque","[2, 3, 20, 91]","['<S sid=""2"" ssid=""2"">We show how a datadriven deterministic dependency parser, in itself restricted to projective structures, can be combined with graph transformation techniques to produce non-projective structures.</S>', '<S sid=""3"" ssid=""3"">Experiments using data from the Prague Dependency Treebank show that the combined system can handle nonprojective constructions with a precision sufficient to yield a significant improvement in overall parsing accuracy.</S>', '<S sid=""20"" ssid=""16"">In this paper, we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques.</S>', '<S sid=""91"" ssid=""2"">Table 5 shows the overall parsing accuracy attained with the three different encoding schemes, compared to the baseline (no special arc labels) and to training directly on non-projective dependency graphs.</S>']","Method_Citation,Results_Citation"
4,P05-1013,P12-3029,0,"Nivre and Nilsson, 2005",0,"For tree banks with non-projective trees weuse the pseudo-projective parsing technique to trans form the tree bank into projective structures (Nivre and Nilsson, 2005)","For tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (Nivre and Nilsson, 2005)","[1, 2, 8, 109]","['<S sid=""1"" ssid=""1"">In order to realize the full potential of dependency-based syntactic parsing, it is desirable to allow non-projective dependency structures.</S>', '<S sid=""2"" ssid=""2"">We show how a datadriven deterministic dependency parser, in itself restricted to projective structures, can be combined with graph transformation techniques to produce non-projective structures.</S>', '<S sid=""8"" ssid=""4"">Thus, most broad-coverage parsers based on dependency grammar have been restricted to projective structures.</S>', '<S sid=""109"" ssid=""1"">We have presented a new method for non-projective dependency parsing, based on a combination of data-driven projective dependency parsing and graph transformation techniques.</S>']","Method_Citation,Results_Citation"
5,P05-1013,W10-1403,0,"Nivre and Nilsson, 2005",0,"It uses graph transformation to handle non-projective trees (Nivre and Nilsson, 2005)","It uses graph transformation to handle non-projective trees (Nivre and Nilsson, 2005)","[0, 2, 60, 109]","['<S sid=""0"">Pseudo-Projective Dependency Parsing</S>', '<S sid=""2"" ssid=""2"">We show how a datadriven deterministic dependency parser, in itself restricted to projective structures, can be combined with graph transformation techniques to produce non-projective structures.</S>', '<S sid=""60"" ssid=""31"">In section 4 we evaluate these transformations with respect to projectivized dependency treebanks, and in section 5 they are applied to parser output.</S>', '<S sid=""109"" ssid=""1"">We have presented a new method for non-projective dependency parsing, based on a combination of data-driven projective dependency parsing and graph transformation techniques.</S>']",Method_Citation
6,P05-1013,D08-1008,0,"Nivre and Nilsson, 2005",0,"To simplify implementation, we instead opted for the pseudo-projective approach (Nivre and Nilsson,2005), in which non projective links are lifted upwards in the tree to achieve projectivity, and special trace labels are used to enable recovery of the non projective links at parse time","To simplify implementation, we instead opted for the pseudo-projective approach (Nivre and Nilsson, 2005), in which non projective links are lifted upwards in the tree to achieve projectivity, and special trace labels are used to enable recovery of the non projective links at parse time","[22, 94, 95, 104]","['<S sid=""22"" ssid=""18"">When the parser is trained on the transformed data, it will ideally learn not only to construct projective dependency structures but also to assign arc labels that encode information about lifts.</S>', '<S sid=""94"" ssid=""5"">The first thing to note is that projectivizing helps in itself, even if no encoding is used, as seen from the fact that the projective baseline outperforms the non-projective training condition by more than half a percentage point on attachment score, although the gain is much smaller with respect to exact match.</S>', '<S sid=""95"" ssid=""6"">The second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.</S>', '<S sid=""104"" ssid=""15"">The overall parsing accuracy obtained with the pseudo-projective approach is still lower than for the best projective parsers.</S>']",Method_Citation
7,P05-1013,D07-1013,0,2005,0,",wn in O (n) time, producing a projective dependency graph satisfying conditions 1? 4 in section 2.1, possibly after adding arcs (0, i ,lr) for every node i 6= 0 that is a root in the output graph (where lr is a special label for root modifiers) .Nivre and Nilsson (2005) showed how the restriction to projective dependency graphs could be lifted by using graph transformation techniques to pre process training data and post-process parser output, so-called pseudo-projective parsing. To learn transition scores, these systems use discriminative learning methods ,e.g., memory-based learning or support vector machines","Nivre and Nilsson (2005) showed how the restriction to projective dependency graphs could be lifted by using graph transformation techniques to preprocess training data and post-process parser output, so-called pseudo-projective parsing","[2, 20, 21, 22]","['<S sid=""2"" ssid=""2"">We show how a datadriven deterministic dependency parser, in itself restricted to projective structures, can be combined with graph transformation techniques to produce non-projective structures.</S>', '<S sid=""20"" ssid=""16"">In this paper, we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques.</S>', '<S sid=""21"" ssid=""17"">First, the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al., 1998) and encoding information about these lifts in arc labels.</S>', '<S sid=""22"" ssid=""18"">When the parser is trained on the transformed data, it will ideally learn not only to construct projective dependency structures but also to assign arc labels that encode information about lifts.</S>']","Method_Citation,Results_Citation"
8,P05-1013,D07-1119,0,2005,0,"For handling non-projective relations, Nivre and Nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective","For handling non-projective relations, Nivre and Nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective","[22, 36, 37, 41]","['<S sid=""22"" ssid=""18"">When the parser is trained on the transformed data, it will ideally learn not only to construct projective dependency structures but also to assign arc labels that encode information about lifts.</S>', '<S sid=""36"" ssid=""7"">As observed by Kahane et al. (1998), any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation, which replaces each non-projective arc wj wk by a projective arc wi &#8212;* wk such that wi &#8212;*&#8727; wj holds in the original graph.</S>', '<S sid=""37"" ssid=""8"">Here we use a slightly different notion of lift, applying to individual arcs and moving their head upwards one step at a time: Intuitively, lifting an arc makes the word wk dependent on the head wi of its original head wj (which is unique in a well-formed dependency graph), unless wj is a root in which case the operation is undefined (but then wj &#8212;* wk is necessarily projective if the dependency graph is well-formed).</S>', '<S sid=""41"" ssid=""12"">Applying the function PROJECTIVIZE to the graph in Figure 1 yields the graph in Figure 2, where the problematic arc pointing to Z has been lifted from the original head jedna to the ancestor je.</S>']",Method_Citation
9,P05-1013,N07-1050,0,"Nivre and Nilsson, 2005",0,"Whereas most of the early approaches were limited to strictly projective dependency structures, where the projection of a syntactic head must be continuous, attention has recently shifted to the analysis of non-projective structures, which are required for linguistically adequate representations, especially in languages with free or flexible word order. The most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of a strictly projective dependency parser, as in pseudo-projective parsing (Nivre and Nilsson, 2005), corrective modeling (Hall and Nova? k, 2005), or approximate non-projective parsing (McDonald and Pereira, 2006)","The most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of a strictly projective dependency parser, as in pseudo-projective parsing (Nivre and Nilsson, 2005), corrective modeling (Hall and Nova? k, 2005), or approximate non-projective parsing (McDonald and Pereira, 2006)","[2, 9, 22, 109]","['<S sid=""2"" ssid=""2"">We show how a datadriven deterministic dependency parser, in itself restricted to projective structures, can be combined with graph transformation techniques to produce non-projective structures.</S>', '<S sid=""9"" ssid=""5"">This is true of the widely used link grammar parser for English (Sleator and Temperley, 1993), which uses a dependency grammar of sorts, the probabilistic dependency parser of Eisner (1996), and more recently proposed deterministic dependency parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004).</S>', '<S sid=""22"" ssid=""18"">When the parser is trained on the transformed data, it will ideally learn not only to construct projective dependency structures but also to assign arc labels that encode information about lifts.</S>', '<S sid=""109"" ssid=""1"">We have presented a new method for non-projective dependency parsing, based on a combination of data-driven projective dependency parsing and graph transformation techniques.</S>']",Results_Citation
10,P05-1013,W09-1207,0,"Nivre and Nilsson, 2005",0,"troduced in (Nivre and Nilsson, 2005) to handle the non-projective languages including Czech, German and English","We adopt the pseudo-projective approach introduced in (Nivre and Nilsson, 2005) to handle the non-projective languages including Czech, German and English","[3, 4, 8, 17]","['<S sid=""3"" ssid=""3"">Experiments using data from the Prague Dependency Treebank show that the combined system can handle nonprojective constructions with a precision sufficient to yield a significant improvement in overall parsing accuracy.</S>', '<S sid=""4"" ssid=""4"">This leads to the best reported performance for robust non-projective parsing of Czech.</S>', '<S sid=""8"" ssid=""4"">Thus, most broad-coverage parsers based on dependency grammar have been restricted to projective structures.</S>', '<S sid=""17"" ssid=""13"">There exist a few robust broad-coverage parsers that produce non-projective dependency structures, notably Tapanainen and J&#168;arvinen (1997) and Wang and Harper (2004) for English, Foth et al. (2004) for German, and Holan (2004) for Czech.</S>']","Method_Citation,Results_Citation"
11,P05-1013,E09-1034,0,"Nivre and Nilsson, 2005",0,"non projective (Nivre and Nilsson, 2005), we char ac terise a sense in which the structures appearing in tree banks can be viewed as being only? slightly? ill-nested","However, just as it has been noted that most non-projective structures appearing in practice are only 'slightly' non projective (Nivre and Nilsson, 2005), we characterise a sense in which the structures appearing in tree banks can be viewed as being only 'slightly' ill-nested","[7, 8, 16, 24]","['<S sid=""7"" ssid=""3"">From the point of view of computational implementation this can be problematic, since the inclusion of non-projective structures makes the parsing problem more complex and therefore compromises efficiency and in practice also accuracy and robustness.</S>', '<S sid=""8"" ssid=""4"">Thus, most broad-coverage parsers based on dependency grammar have been restricted to projective structures.</S>', '<S sid=""16"" ssid=""12"">Still, from a theoretical point of view, projective parsing of non-projective structures has the drawback that it rules out perfect accuracy even as an asymptotic goal.</S>', '<S sid=""24"" ssid=""20"">We call this pseudoprojective dependency parsing, since it is based on a notion of pseudo-projectivity (Kahane et al., 1998).</S>']",Method_Citation
12,P05-1013,W09-1218,0,"Nivre and Nilsson, 2005",0,"In order to avoid losing the benefits of higher-order parsing, we considered applying pseudo-projective transformation (Nivre and Nilsson, 2005)","In order to avoid losing the benefits of higher-order parsing, we considered applying pseudo-projective transformation (Nivre and Nilsson, 2005)","[0, 1, 65, 95]","['<S sid=""0"">Pseudo-Projective Dependency Parsing</S>', '<S sid=""1"" ssid=""1"">In order to realize the full potential of dependency-based syntactic parsing, it is desirable to allow non-projective dependency structures.</S>', '<S sid=""65"" ssid=""4"">More details on the parsing algorithm can be found in Nivre (2003).</S>', '<S sid=""95"" ssid=""6"">The second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.</S>']",Method_Citation
13,P05-1013,C08-1081,0,"Nivre and Nilsson, 2005",0,"Pseudo-projective parsing for recovering non projective structures (Nivre and Nilsson, 2005)","Pseudo-projective parsing for recovering non projective structures (Nivre and Nilsson, 2005)","[0, 8, 65, 104]","['<S sid=""0"">Pseudo-Projective Dependency Parsing</S>', '<S sid=""8"" ssid=""4"">Thus, most broad-coverage parsers based on dependency grammar have been restricted to projective structures.</S>', '<S sid=""65"" ssid=""4"">More details on the parsing algorithm can be found in Nivre (2003).</S>', '<S sid=""104"" ssid=""15"">The overall parsing accuracy obtained with the pseudo-projective approach is still lower than for the best projective parsers.</S>']",Method_Citation
14,P05-1013,C08-1081,0,2005,0,"Although the parser only derives projective graphs, the fact that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of Nivre and Nilsson (2005) (section 3.4)","Although the parser only derives projective graphs, the fact that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of Nivre and Nilsson (2005) (section 3.4)","[0, 1, 2, 62]","['<S sid=""0"">Pseudo-Projective Dependency Parsing</S>', '<S sid=""1"" ssid=""1"">In order to realize the full potential of dependency-based syntactic parsing, it is desirable to allow non-projective dependency structures.</S>', '<S sid=""2"" ssid=""2"">We show how a datadriven deterministic dependency parser, in itself restricted to projective structures, can be combined with graph transformation techniques to produce non-projective structures.</S>', '<S sid=""62"" ssid=""1"">In the experiments below, we employ a data-driven deterministic dependency parser producing labeled projective dependency graphs,3 previously tested on Swedish (Nivre et al., 2004) and English (Nivre and Scholz, 2004).</S>']",Method_Citation
15,P05-1013,C08-1081,0,2005,0,Pseudo-projective parsing was proposed by Nivreand Nilsson (2005) as a way of dealing with non projective structures in a projective data-driven parser,Pseudo-projective parsing was proposed by Nivreand Nilsson (2005) as a way of dealing with non projective structures in a projective data-driven parser,"[1, 8, 61, 104]","['<S sid=""1"" ssid=""1"">In order to realize the full potential of dependency-based syntactic parsing, it is desirable to allow non-projective dependency structures.</S>', '<S sid=""8"" ssid=""4"">Thus, most broad-coverage parsers based on dependency grammar have been restricted to projective structures.</S>', '<S sid=""61"" ssid=""32"">Before we turn to the evaluation, however, we need to introduce the data-driven dependency parser used in the latter experiments.</S>', '<S sid=""104"" ssid=""15"">The overall parsing accuracy obtained with the pseudo-projective approach is still lower than for the best projective parsers.</S>']","Method_Citation,Results_Citation"
16,P05-1013,C08-1081,0,2005,0,"Weprojectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called HEAD by Nivre and Nilsson (2005), which means that a lifted arc is assigned the label r? h, where r is the original label and h is the label of the original head in the non-projective dependency graph","We projectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called HEAD by Nivre and Nilsson (2005), which means that a lifted arc is assigned the label r? h, where r is the original label and h is the label of the original head in the non-projective dependency graph","[22, 37, 49, 50]","['<S sid=""22"" ssid=""18"">When the parser is trained on the transformed data, it will ideally learn not only to construct projective dependency structures but also to assign arc labels that encode information about lifts.</S>', '<S sid=""37"" ssid=""8"">Here we use a slightly different notion of lift, applying to individual arcs and moving their head upwards one step at a time: Intuitively, lifting an arc makes the word wk dependent on the head wi of its original head wj (which is unique in a well-formed dependency graph), unless wj is a root in which case the operation is undefined (but then wj &#8212;* wk is necessarily projective if the dependency graph is well-formed).</S>', '<S sid=""49"" ssid=""20"">The baseline simply retains the original labels for all arcs, regardless of whether they have been lifted or not, and the number of distinct labels is therefore simply the number n of distinct dependency types.2 In the first encoding scheme, called Head, we use a new label d&#8593;h for each lifted arc, where d is the dependency relation between the syntactic head and the dependent in the non-projective representation, and h is the dependency relation that the syntactic head has to its own head in the underlying structure.</S>', '<S sid=""50"" ssid=""21"">Using this encoding scheme, the arc from je to Z in Figure 2 would be assigned the label AuxP&#8593;Sb (signifying an AuxP that has been lifted from a Sb).</S>']",Method_Citation
17,P05-1013,D11-1006,0,"Nivre and Nilsson, 2005",0,"For tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (Nivre and Nilsson, 2005)","For tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (Nivre and Nilsson, 2005)","[1, 2, 8, 109]","['<S sid=""1"" ssid=""1"">In order to realize the full potential of dependency-based syntactic parsing, it is desirable to allow non-projective dependency structures.</S>', '<S sid=""2"" ssid=""2"">We show how a datadriven deterministic dependency parser, in itself restricted to projective structures, can be combined with graph transformation techniques to produce non-projective structures.</S>', '<S sid=""8"" ssid=""4"">Thus, most broad-coverage parsers based on dependency grammar have been restricted to projective structures.</S>', '<S sid=""109"" ssid=""1"">We have presented a new method for non-projective dependency parsing, based on a combination of data-driven projective dependency parsing and graph transformation techniques.</S>']",Method_Citation
18,P05-1013,P11-2121,0,"Nivre and Nilsson, 2005",0,"Since the number of non-projective dependencies is much smaller than the number of projective dependencies (Nivre and Nilsson, 2005), it is not efficient to perform non-projective parsing for all cases","Since the number of non-projective dependencies is much smaller than the number of projective dependencies (Nivre and Nilsson, 2005), it is not efficient to perform non-projective parsing for all cases","[19, 20, 39, 109]","['<S sid=""19"" ssid=""15"">Finally, since non-projective constructions often involve long-distance dependencies, the problem is closely related to the recovery of empty categories and non-local dependencies in constituency-based parsing (Johnson, 2002; Dienes and Dubey, 2003; Jijkoun and de Rijke, 2004; Cahill et al., 2004; Levy and Manning, 2004; Campbell, 2004).</S>', '<S sid=""20"" ssid=""16"">In this paper, we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques.</S>', '<S sid=""39"" ssid=""10"">However, since we want to preserve as much of the original structure as possible, we are interested in finding a transformation that involves a minimal number of lifts.</S>', '<S sid=""109"" ssid=""1"">We have presented a new method for non-projective dependency parsing, based on a combination of data-driven projective dependency parsing and graph transformation techniques.</S>']",Method_Citation
19,P05-1013,E06-1010,0,"Nivre and Nilsson, 2005",0,"Itshould be noted that the proportion of lost dependencies is about twice as high as the proportion of dependencies that are non-projective in them selves (Nivre and Nilsson, 2005)","It should be noted that the proportion of lost dependencies is about twice as high as the proportion of dependencies that are non-projective in themselves (Nivre and Nilsson, 2005)","[1, 13, 14, 80]","['<S sid=""1"" ssid=""1"">In order to realize the full potential of dependency-based syntactic parsing, it is desirable to allow non-projective dependency structures.</S>', '<S sid=""13"" ssid=""9"">The fact that projective dependency parsers can never exactly reproduce the analyses found in non-projective treebanks is often neglected because of the relative scarcity of problematic constructions.</S>', '<S sid=""14"" ssid=""10"">While the proportion of sentences containing non-projective dependencies is often 15&#8211;25%, the total proportion of non-projective arcs is normally only 1&#8211;2%.</S>', '<S sid=""80"" ssid=""7"">As shown in Table 3, the proportion of sentences containing some non-projective dependency ranges from about 15% in DDT to almost 25% in PDT.</S>']","Method_Citation,Results_Citation"
20,P05-1013,D07-1111,0,"Nivre and Nilsson, 2005",0,"The resulting algorithm is projective, and nonprojectivity is handled by pseudo-projective trans formations as described in (Nivre and Nilsson, 2005)","The resulting algorithm is projective, and nonprojectivity is handled by pseudo-projective transformations as described in (Nivre and Nilsson, 2005)","[1, 65, 95, 104]","['<S sid=""1"" ssid=""1"">In order to realize the full potential of dependency-based syntactic parsing, it is desirable to allow non-projective dependency structures.</S>', '<S sid=""65"" ssid=""4"">More details on the parsing algorithm can be found in Nivre (2003).</S>', '<S sid=""95"" ssid=""6"">The second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.</S>', '<S sid=""104"" ssid=""15"">The overall parsing accuracy obtained with the pseudo-projective approach is still lower than for the best projective parsers.</S>']",Method_Citation
