Bilingual topic models for parallel texts with word-to-word alignments have been studied previously using the HM-bitam model ( Zhao and Xing , 2007 ) . We employ a set of direct translations , the EuroParl corpus , to evaluate whether PLTM can accurately infer topics when documents genuinely contain the same content . More than 350 topics in the Finnish LDA model have zero tokens assigned to them , and almost all tokens are assigned to the largest 200 topics . 8221 ; language ( E ) : Wte and Wtt , respectively . Tam , Lane and Schultz ( Tam et al. , 2007 ) also show improvements in machine translation using bilingual topic models . In order to make the task more difficult , we train a relatively coarse-grained PLTM with 50 topics on the training set . Table 3 shows mean JS divergences for each value of p. We employ a set of direct translations , the EuroParl corpus , to evaluate whether PLTM can accurately infer topics when documents genuinely contain the same content . Bilingual topic models for parallel texts with word-to-word alignments have been studied previously using the HM-bitam model ( Zhao and Xing , 2007 ) . The second corpus , Wikipedia articles in twelve languages , contains sets of documents that are not translations of one another , but are very likely to be about similar concepts . We use both Jensen-Shannon divergence and cosine distance . We take a simpler approach