Think of DCS as a higher-level Our system learns lexical associations between programming language tailored to natural language , words and predicates . Let z be a DCS tree . Supervised semantic parsers ( Zelle and Mooney , 1996 ; Tang and Mooney , 2001 ; Ge and Mooney , 2005 ; Zettlemoyer and Collins , 2005 ; Kate and Mooney , 2007 ; Zettlemoyer and Collins , 2007 ; Wong and Mooney , 2007 ; Kwiatkowski et al. , 2010 ) rely on manual annotation of logical forms , which is expensive . Let z be a DCS tree . ( 2010 ) , we obviate the need for annotated logical forms by considering the endto-end problem of mapping questions to answers . Model We now present our discriminative semantic parsing model , which places a log-linear distribution over z & As in Clarke et al . This option is not available to us since we do not have annotated logical forms , so we must instead rely on lexical triggers to define the search space . Let z be a DCS tree . Computation We can compute the denotation JzKw of a DCS tree z by exploiting dynamic programming on trees ( Dechter , 2003 ) . As another example , w ( average ) = { ( S , & # 175 ; x ) : We write a DCS tree z as hp ; r1 : c1 ; ... In this paper , we learn to