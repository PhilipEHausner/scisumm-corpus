First , the training data for the parser is projectivized by applying a minimal number of lifting operations ( Kahane et al. , 1998 ) and encoding information about these lifts in arc labels . In section 2 we introduce the graph transformation techniques used to projectivize and deprojectivize dependency graphs , and in section 3 we describe the data-driven dependency parser that is the core of our system . First , the training data for the parser is projectivized by applying a minimal number of lifting operations ( Kahane et al. , 1998 ) and encoding information about these lifts in arc labels . In section 2 we introduce the graph transformation techniques used to projectivize and deprojectivize dependency graphs , and in section 3 we describe the data-driven dependency parser that is the core of our system . 168 ; arvinen ( 1997 ) and Wang and Harper ( 2004 ) for English , Foth et al . As observed by Kahane et al . The first thing to note is that projectivizing helps in itself , even if no encoding is used , as seen from the fact that the projective baseline outperforms the non-projective training condition by more than half a percentage point on attachment score , although the gain is much smaller with respect to exact match . It is sometimes claimed that one of the advantages of dependency grammar over approaches based on constituency is that it allows a more adequate treatment of languages