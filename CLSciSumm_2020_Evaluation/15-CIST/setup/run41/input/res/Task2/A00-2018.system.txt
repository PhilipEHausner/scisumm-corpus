As already noted , Char97 first guesses the lexical head of a constituent and then , given the head , guesses the PCFG rule used to expand the constituent in question . We present a new parser for parsing down to Penn tree-bank style parse trees [ 16 ] that achieves 90.1 % average precision/recall for sentences of length & lt ; 40 , and 89.5 % for sentences of length & lt ; 100 , when trained and tested on the previously established [ 5,9,10,15,17 ] & amp ; quot ; standard & amp ; quot ; sections of the Wall Street Journal tree-bank . The model labeled & amp ; quot ; Old & amp ; quot ; attempts to recreate the Char97 system using the current program . This represents a 13 % decrease in error rate over the best single-parser results on this corpus [ 9 ] . Also , the earlier parser uses two techniques not employed in the current parser . Again as standard , we take separate measurements for all sentences of length & lt ; 40 and all sentences of length & lt ; 100 . 8212 ; that is , according to the distributions p ( Li j1 ) , p ( M I 1 ) , and p ( Ri I 1 ) . A Maximum-Entropy-Inspired Parser . In the simplest of such models , a zeroorder Markov grammar , each label on the righthand side is generated conditioned only