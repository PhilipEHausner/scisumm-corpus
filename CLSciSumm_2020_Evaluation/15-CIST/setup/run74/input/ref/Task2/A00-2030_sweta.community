Almost all approaches to information extraction &#8212; even at the sentence level &#8212; are based on the divide-and-conquer strategy of reducing a complex problem to a set of simpler ones. Given multiple constituents that cover identical spans in the chart, only those constituents with probabilities within a While our focus throughout the project was on TE and TR, we became curious about how well the model did at part-of-speech tagging, syntactic parsing, and at name finding. In this section, we describe the algorithm that was used to automatically produce augmented trees, starting with a) human-generated semantic annotations and b) machinegenerated syntactic parse trees. In these trees, the standard TREEBANK structures are augmented to convey semantic information, that is, entities and relations. Since 1995, a few statistical parsing algorithms have demonstrated a breakthrough in parsing accuracy, as measured against the UPenn TREEBANK as a gold standard. The detailed probability structure differs, however, in that it was designed to jointly perform part-of-speech tagging, name finding, syntactic parsing, and relation finding in a single process.</S We have demonstrated, at least for one problem, that a lexicalized, probabilistic context-free parser with head rules (LPCFGHR) can be used effectively for information extraction. Because generative statistical models had already proven successful for each of the first three stages, we were optimistic that some of their properties &#8212; especially their ability to learn from large amounts of data, and their robustness when presented with unexpected inputs &#8212; would also benefit semantic analysis. In this paper we report adapting a lexic al ized, probabilistic context-free parser to information extraction and evaluate this new technique on MUC-7 template elements and template relations. The detailed probability structure differs, however, in that it was designed to jointly perform part-of-speech tagging, name finding, syntactic parsing, and relation finding in a single process. Our integrated model represents syntax and semantics jointly using augmented parse trees. Since 1995, a few statistical parsing algorithms (Magerman, 1995; Collins, 1996 and 1997; Charniak, 1997; Rathnaparki, 1997) demonstrated a breakthrough in parsing accuracy, as measured against the University of Pennsylvania TREEBANK as a gold standard. In this paper we report adapting a lexic al ized, probabilistic context-free parser to information extraction and evaluate this new technique on MUC-7 template elements and template relations.< We have demonstrated, at least for one problem, that a lexicalized, probabilistic context-free parser with head rules (LPCFGHR) can be used effectively for information extraction The detailed probability structure differs, however, in that it was designed to jointly perform part-of-speech tagging, name finding, syntactic parsing, and relation finding in a single process.
