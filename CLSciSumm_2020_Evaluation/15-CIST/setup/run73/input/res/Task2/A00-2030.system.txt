We evaluated the new approach to information extraction on two of the tasks of the Seventh Message Understanding Conference (MUC-7) and reported in (Marsh, 1998). Further details are discussed in the section Tree Augmentation. In this section, we describe the algorithm that was used to automatically produce augmented trees, starting with a) human-generated semantic annotations and b) machinegenerated syntactic parse trees. We illustrate the generation process by walking through a few of the steps of the parse shown in Figure 3. Almost all approaches to information extraction &#8212; even at the sentence level &#8212; are based on the divide-and-conquer strategy of reducing a complex problem to a set of simpler ones. An integrated model can limit the propagation of errors by making all decisions jointly. The detailed probability structure differs, however, in that it was designed to jointly perform part-of-speech tagging, name finding, syntactic parsing, and relation finding in a single process. For each constituent, the head is generated first, followed by the modifiers, which are generated from the head outward. Instead, our parsing algorithm, trained on the UPenn TREEBANK, was run on the New York Times source to create unsupervised syntactic training which was constrained to be consistent with semantic annotation. The semantic training corpus was produced by students according to a simple set of guidelines. This simple semantic annotation was the only source of task knowledge used to configure the model. Although each model differed in its detailed probability structure, we believed that the essential elements of all