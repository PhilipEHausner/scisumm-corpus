If the model assigns topics uniformly , the maximum topic probability will be near 1/T . 8212 ; it is clear from the examples in figure 2 that the sets of high probability words in different languages for a given topic are likely to include translations . Although the PLTM is clearly not a substitute for a machine translation system & We then add the Cartesian product of these sets for every topic to a set of candidate translations C. One simple way to achieve this topic alignment is to add a small set of comparable document tuples that provide sufficient & No paper is exactly comparable to any other paper , but they are all roughly topically similar . In order to simulate this scenario we create a set of variations of the EuroParl corpus by treating some documents as if they have no parallel/comparable texts & We then add the Cartesian product of these sets for every topic to a set of candidate translations C. If the model assigns topics uniformly , the maximum topic probability will be near 1/T . One simple way to achieve this topic alignment is to add a small set of comparable document tuples that provide sufficient & Although the PLTM is clearly not a substitute for a machine translation system & We use this corpus to explore the ability of the model both to infer similarities between vocabularies in different languages , and to detect differences in topic emphasis between languages .