Pseudo-Projective Dependency Parsin . When the parser is trained on the transformed data , it will ideally learn not only to construct projective dependency structures but also to assign arc labels that encode information about lifts . We have presented a new method for non-projective dependency parsing , based on a combination of data-driven projective dependency parsing and graph transformation techniques . When the parser is trained on the transformed data , it will ideally learn not only to construct projective dependency structures but also to assign arc labels that encode information about lifts . Here we use a slightly different notion of lift , applying to individual arcs and moving their head upwards one step at a time : Intuitively , lifting an arc makes the word wk dependent on the head wi of its original head wj ( which is unique in a well-formed dependency graph ) , unless wj is a root in which case the operation is undefined ( but then wj & # 8212 ; * wk is necessarily projective if the dependency graph is well-formed ) . Pseudo-Projective Dependency Parsin . The first thing to note is that projectivizing helps in itself , even if no encoding is used , as seen from the fact that the projective baseline outperforms the non-projective training condition by more than half a percentage point on attachment score , although the gain is much smaller with respect to exact match . From the point of view of computational