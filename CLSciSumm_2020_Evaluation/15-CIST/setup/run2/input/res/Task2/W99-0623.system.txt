Finally we show the combining techniques degrade very little when a poor parser is added to the set . Finally we show the combining techniques degrade very little when a poor parser is added to the set . The first row represents the average accuracy of the three parsers we combine . 239 ; ve Bayes classifier to determine which constituents to include in the parse . We call this approach parse hybridization . The first row represents the average accuracy of the three parsers we combine . We used these three parsers to explore parser combination techniques . The combining algorithm is presented with the candidate parses and asked to choose which one is best . Finally we show the combining techniques degrade very little when a poor parser is added to the set . We have presented two general approaches to studying parser combination : parser switching and parse hybridization . None of the models we have presented utilize features associated with a particular constituent ( i.e . the label , span , parent label , etc . ) to influence parser preference . r ( c ) is a binary function returning t ( for true ) precisely when the constituent c E C should be included in the hypothesis . The Bayes models were able to achieve significantly higher precision than their non-parametric counterparts . C is the union of the sets of constituents suggested by the parsers . While we can not prove there are