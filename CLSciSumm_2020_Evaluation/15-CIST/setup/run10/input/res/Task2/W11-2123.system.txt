KenLM: Faster and Smaller Language Model Querie. Throughout this paper we compare with several packages: SRILM 1.5.12 (Stolcke, 2002) is a popular toolkit based on tries used in several decoders. SRILM (Stolcke, 2002) is widely used within academia. We have described two data structures for language modeling that achieve substantial reductions in time and memory cost. We present KenLM, a library that implements two data structures for efficient language model queries, reducing both time and costs. The binary language model from Section 5.2 and text phrase table were forced into disk cache before each run. Time for Moses itself to load, including loading the language model and phrase table, is included. Therefore, we want state to encode the minimum amount of information necessary to properly compute language model scores, so that the decoder will be faster and make fewer search errors. The returned state s(wn1) may then be used in a followon query p(wn+1js(wn1)) that extends the previous query by one word. If the context wnf will never extend to the right (i.e. wnf v is not present in the model for all words v) then no subsequent query will match the full context. All language model queries issued by machine translation decoders follow a left-to-right pattern, starting with either the begin of sentence token or null context for mid-sentence fragments. Performance improvements transfer to the Moses (Koehn et al., 2007), cdec (Dyer et al., 2010), and Joshua (Li et al., 2009) translation systems where our code has been integrated.