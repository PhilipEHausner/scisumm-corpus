Most DOP models , such as in Bod ( 1993 ) , Goodman ( 1996 ) , Bonnema et al . Bonnema et al . In Bod ( 2000b ) , an alternative notion for the best parse tree was proposed based on a simplicity criterion : instead of producing the most probable tree , this model produced the tree generated by the shortest derivation with the fewest training subtrees . We will refer to these models as Likelihood-DOP models , but in this paper we will specifically mean by & amp ; quot ; Likelihood-DOP & amp ; quot ; the PCFG-reduction of Bod ( 2001 ) given in Section 2.2 . For example , Bod ( 2001 ) samples a fixed number of subtrees of each depth , which has the effect of assigning roughly equal weight to each node in the training data , and roughly exponentially less probability for larger trees ( see Goodman 2002 : 12 ) . Collins & amp ; Duffy ( 2002 ) showed how the perceptron algorithm can be used to efficiently compute the best parse with DOP1\ 's subtrees , reporting a 5.1 % relative reduction in error rate over the model in Collins ( 1999 ) on the WSJ . Collins & amp ; Duffy ( 2002 ) showed how the perceptron algorithm can be used to efficiently compute the best parse with DOP1\ 's subtrees , reporting a 5.1 % relative reduction in error rate over the model