( Actually , we use a minor variant described in [ 4 ] .. We created a parser based upon the maximumentropy-inspired model of the last section , smoothed using standard deleted interpolation . In keeping with the standard methodology [ 5 , 9,10,15,17 ] , we used the Penn Wall Street Journal tree-bank [ 16 ] with sections 2-21 for training , section 23 for testing , and section 24 for development ( debugging and tuning ) . This is as opposed to the & amp ; quot ; Markovgrammar & amp ; quot ; approach used in the current parser . We present a new parser for parsing down to Penn tree-bank style parse trees [ 16 ] that achieves 90.1 % average precision/recall for sentences of length & lt ; 40 , and 89.5 % for sentences of length & lt ; 100 , when trained and tested on the previously established [ 5,9,10,15,17 ] & amp ; quot ; standard & amp ; quot ; sections of the Wall Street Journal tree-bank . This is as opposed to the & amp ; quot ; Markovgrammar & amp ; quot ; approach used in the current parser . We present a new parser for parsing down to Penn tree-bank style parse trees [ 16 ] that achieves 90.1 % average precision/recall for sentences of length & lt ; 40 , and 89.5 % for sentences of length & lt ; 100 , when trained and tested on