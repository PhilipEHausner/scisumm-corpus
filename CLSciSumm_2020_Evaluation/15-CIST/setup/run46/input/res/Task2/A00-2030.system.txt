We evaluated the new approach to information extraction on two of the tasks of the Seventh Message Understanding Conference (MUC-7) and reported in (Marsh, 1998). Further details are discussed in the section Tree Augmentation. In this section, we describe the algorithm that was used to automatically produce augmented trees, starting with a) human-generated semantic annotations and b) machinegenerated syntactic parse trees. Word features are introduced primarily to help with unknown words, as in (Weischedel et al. 1993). For this reason, we focused on designing an integrated model in which tagging, namefinding, parsing, and semantic interpretation decisions all have the opportunity to mutually influence each other. In our statistical model, trees are generated according to a process similar to that described in (Collins 1996, 1997). If we generalize the tree components (constituent labels, words, tags, etc.) and treat them all as simply elements, e, and treat all the conditioning factors as the history, h, we can write. Given multiple constituents that cover identical spans in the chart, only those constituents with probabilities within a While our focus throughout the project was on TE and TR, we became curious about how well the model did at part-of-speech tagging, syntactic parsing, and at name finding. Instead, our parsing algorithm, trained on the UPenn TREEBANK, was run on the New York Times source to create unsupervised syntactic training which was constrained to be consistent with semantic annotation. Figure 4 shows an example of the semantic annotation, which was the only type of manual annotation