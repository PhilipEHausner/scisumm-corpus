To segment and tag a character sequence , there are two strategies to choose : performing POS tagging following segmentation ; or joint segmentation and POS tagging ( Joint S & amp ; T ) . 955 ; tw denote the corresponding weights of the two components . We called them non-lexical-target because predications derived from them can predicate without considering the current character C0 . Using W = w1 : m to denote the word sequence , T = t1 : m to denote the corresponding POS sequence , P ( T |W ) to denote the probability that W is labelled as T , and P ( W|T ) to denote the probability that T generates W , we can define the cooccurrence model as follows : & The first was conducted to test the performance of the perceptron on segmentation on the corpus from SIGHAN Bakeoff 2 , including the Academia Sinica Corpus ( AS ) , the Hong Kong City University Corpus ( CityU ) , the Peking University Corpus ( PKU ) and the Microsoft Research Corpus ( MSR ) . As a result , many theoretically useful features such as higherorder word or POS n-grams are difficult to be incorporated in the model efficiently . 955 ; wt and & We add a field C0 to each template in the upper column , so that it can carry out predication according to not only the context but also the current character itself . Using