Conversely , when color is combined with ran , the resulting vector will be closer to dissolve than gallop . For additive models , a natural way to achieve this is to include further vectors into the summation . For example , assuming that individual words are represented by vectors , we can compute the meaning of a sentence by taking their mean ( Foltz et al. , 1998 ; Landauer and Dumais , 1997 ) . Despite the popularity of additive models , our experimental results showed the superiority of models utilizing multiplicative combinations , at least for the sentence similarity task attempted here . For additive models , a natural way to achieve this is to include further vectors into the summation . He argues that the subjects of ran in The color ran and The horse ran select different senses of ran . In this paper we examine models of semantic composition that are empirically grounded and can represent similarity relations . Smolensky ( 1990 ) proposed the use of tensor products as a means of binding one vector to another . In this paper we examine models of semantic composition that are empirically grounded and can represent similarity relations . The models considered so far assume that components do not & Conversely , when color is combined with ran , the resulting vector will be closer to dissolve than gallop . 8217 ; with each other , i.e. Smolensky ( 1990 ) proposed the use of