This paper discusses the use of unlabeled examples for the problem of named entity classification. This paper discusses the use of unlabeled examples for the problem of named entity classification. (Yarowsky 95) describes an algorithm for word-sense disambiguation that exploits redundancy in contextual features, and gives impressive performance. Unfortunately, Yarowsky\'s method is not well understood from a theoretical viewpoint: we would like to formalize the notion of redundancy in unlabeled data, and set up the learning task as optimization of some appropriate objective function. The second algorithm builds on a boosting algorithm called AdaBoost (Freund and Schapire 97; Schapire and Singer 98). AdaBoost was first introduced in (Freund and Schapire 97); (Schapire and Singer 98) gave a generalization of AdaBoost which we will use in this paper. (3)), with one term for each classifier. The two new terms force the two classifiers to agree, as much as possible, on the unlabeled examples. There are two differences between this method and the DL-CoTrain algorithm: spelling and contextual features, alternating between labeling and learning with the two types of features. The DL-CoTrain algorithm can be motivated as being a greedy method of satisfying the above 2 constraints. (We would like to note though that unlike previous boosting algorithms, the CoBoost algorithm presented here is not a boosting algorithm under Valiant\'s (Valiant 84) Probably Approximately Correct (PAC) model.. This section describes AdaBoost, which is the basis for the CoBoost algorithm. Unsupervised Models for Named Entity Classification Collin. A large number of rules is