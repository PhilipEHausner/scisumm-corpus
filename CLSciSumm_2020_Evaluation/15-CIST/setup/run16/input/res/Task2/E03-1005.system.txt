However, the problem of computing the most probable parse turns out to be NP-hard (Sima\'an 1996), mainly because the same parse tree can be generated by exponentially many derivations. The probability of a parse tree T is the sum of the probabilities of its distinct derivations. This means that summing up over derivations of a tree in DOP yields the same probability as summing over all the isomorphic derivations in the PCFG. The derivation with the smallest sum, or highest rank, is taken as the final best derivation producing the best parse tree in Simplicity-DOP.3 Although Bod (2000b) reports that Simplicity DOP is outperformed by Likelihood-DOP, its results are still rather impressive for such a simple model. Although Bod\'s method obtains very competitive results on the Wall Street Journal (WSJ) task, the parsing time was reported to be over 200 seconds per sentence (Bod 2003). Collins &amp; Duffy (2002) showed how the perceptron algorithm can be used to efficiently compute the best parse with DOP1\'s subtrees, reporting a 5.1% relative reduction in error rate over the model in Collins (1999) on the WSJ. In the following section first results of SL-DOP and LS-DOP with a compact PCFG-reduction. we will see that our new definition of best parse tree also outperforms the best results obtained in Bod (2001). This paper showed that a PCFG-reduction of DOP in combination with a new notion of the best parse tree results in fast processing times and very competitive accuracy on the Wall Street Journal