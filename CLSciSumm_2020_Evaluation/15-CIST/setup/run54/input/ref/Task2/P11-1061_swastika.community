For comparison, the completely unsupervised feature-HMM baseline accuracy on the universal POS tags for English is 79.4%, and goes up to 88.7% with a treebank dictionary. Because all English vertices are going to be labeled, we do not need to disambiguate them by embedding them in trigrams.</S To this end, we construct a bilingual graph over word types to establish a connection between the two languages (&#167;3), and then use graph label propagation to project syntactic information from English to the foreign language (&#167;4). We hope that this will allow practitioners to apply our approach directly to languages for which no resources are available. The taggers were trained on datasets labeled with the universal tags. We have shown the efficacy of graph-based label propagation for projecting part-of-speech information across languages. Our final average POS tagging accuracy of 83.4% compares very favorably to the average accuracy of Berg-Kirkpatrick et al.&#8217;s monolingual unsupervised state-of-the-art model (73.0%), and considerably bridges the gap to fully supervised POS tagging performance (96.6%). The focus of this work is on building POS taggers for foreign languages, assuming that we have an English POS tagger and some parallel text between the two languages. To bridge this gap, we consider a practically motivated scenario, in which we want to leverage existing resources from a resource-rich language (like English) when building tools for resource-poor foreign languages.1 We assume that absolutely no labeled training data is available for the foreign language of interest, but that we have access to parallel data with a resource-rich language. Our final average POS tagging accuracy of 83.4% compares very favorably to the average accuracy of Berg-Kirkpatrick et al.&#8217;s monolingual unsupervised state-of-the-art model (73.0%), and considerably bridges the gap to fully supervised POS tagging performance (96.6%). To define a similarity function between the English and the foreign vertices, we rely on high-confidence word alignments.</ Our results outperform strong unsupervised baselines as well as approaches that rely on direct projections, and bridge the gap between purely supervised and unsupervised POS tagging models.
