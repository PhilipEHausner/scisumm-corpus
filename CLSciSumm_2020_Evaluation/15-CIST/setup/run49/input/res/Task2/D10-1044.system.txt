Discriminative Instance Weighting for Domain Adaptation in Statistical Machine Translatio. This is a standard adaptation problem for SMT. There is a fairly large body of work on SMT adaptation. Section 2 describes our baseline techniques for SMT adaptation, and section 3 describes the instance-weighting approach. Matsoukas et al (2009) generalize it by learning weights on sentence pairs that are used when estimating relative-frequency phrase-pair probabilities. Phrase tables were extracted from the IN and OUT training corpora (not the dev as was used for instance weighting models), and phrase pairs in the intersection of the IN and OUT phrase tables were used as positive examples, with two alternate definitions of negative examples: The classifier trained using the 2nd definition had higher accuracy on a development set. We have already mentioned the closely related work by Matsoukas et al (2009) on discriminative corpus weighting, and Jiang and Zhai (2007) on (nondiscriminative) instance weighting. We will also directly compare with a baseline similar to the Matsoukas et al approach in order to measure the benefit from weighting phrase pairs (or ngrams) rather than full sentences. Domain adaptation is a common concern when optimizing empirical NLP applications. In this paper we study the problem of using a parallel corpus from a background domain (OUT) to improve performance on a target domain (IN) for which a smaller amount of parallel training material&#8212;though adequate for reasonable performance&#8212;is also available. Moving beyond directly related work, major themes in SMT adaptation include the IR (Hildebrand et al., 2005;