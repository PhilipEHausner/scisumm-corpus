Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P11-1061,P11-1144,0,2011,0,Subramanya et al? s model was extended by Das and Petrov (2011) to induce part-of-speech dictionaries for unsupervised learning of taggers,Subramanya et al's model was extended by Das and Petrov (2011) to induce part-of-speech dictionaries for unsupervised learning of taggers,"'1','8','18','144'","<S sid=""1"" ssid=""1"">We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language.</S><S sid=""8"" ssid=""4"">Unsupervised learning approaches appear to be a natural solution to this problem, as they require only unannotated text for training models.</S><S sid=""18"" ssid=""14"">To make the projection practical, we rely on the twelve universal part-of-speech tags of Petrov et al. (2011).</S><S sid=""144"" ssid=""7"">For comparison, the completely unsupervised feature-HMM baseline accuracy on the universal POS tags for English is 79.4%, and goes up to 88.7% with a treebank dictionary.</S>","Method_Citation,Results_Citation"
3,P11-1061,P14-1126,0,2011,0,"Fortunately, some recently proposed POS taggers, such as the POStagger of Das and Petrov (2011), rely only on labeled training data for English and the same kind of parallel text in our approach","Fortunately, some recently proposed POS taggers, such as the POS tagger of Das and Petrov (2011), rely only on labeled training data for English and the same kind of parallel text in our approach","'1','7','9','24'","<S sid=""1"" ssid=""1"">We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language.</S><S sid=""7"" ssid=""3"">However, supervised methods rely on labeled training data, which is time-consuming and expensive to generate.</S><S sid=""9"" ssid=""5"">Unfortunately, the best completely unsupervised English POS tagger (that does not make use of a tagging dictionary) reaches only 76.1% accuracy (Christodoulopoulos et al., 2010), making its practical usability questionable at best.</S><S sid=""24"" ssid=""1"">The focus of this work is on building POS taggers for foreign languages, assuming that we have an English POS tagger and some parallel text between the two languages.</S>",Results_Citation
4,P11-1061,N12-1086,0,"Das and Petrov, 2011",0,"Applications have ranged from domain adaptation of part-of-speech (POS) taggers (Subramanya et al, 2010), unsupervised learning ofPOS taggers by using bilingual graph-based projections (Das and Petrov, 2011), and shallow semantic parsing for unknown predicates (Das and Smith,2011)","Applications have ranged from domain adaptation of part-of-speech (POS) taggers (Subramanya et al, 2010), unsupervised learning of POS taggers by using bilingual graph-based projections (Das and Petrov, 2011), and shallow semantic parsing for unknown predicates (Das and Smith,2011)","'0','1','2','18'","<S sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S sid=""1"" ssid=""1"">We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language.</S><S sid=""2"" ssid=""2"">Our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages.</S><S sid=""18"" ssid=""14"">To make the projection practical, we rely on the twelve universal part-of-speech tags of Petrov et al. (2011).</S>",Method_Citation
5,P11-1061,N12-1086,0,2011,0,"Following Das and Petrov (2011) and Subramanya et al (2010), a similarity score between two trigram types was computed by measuring the cosine similarity between their empirical sentential context statistics","Following Das and Petrov (2011) and Subramanya et al (2010), a similarity score between two trigram types was computed by measuring the cosine similarity between their empirical sentential context statistics","'28','39','42','47'","<S sid=""28"" ssid=""5"">The edge weights between the foreign language trigrams are computed using a co-occurence based similarity function, designed to indicate how syntactically similar the middle words of the connected trigrams are (&#167;3.2).</S><S sid=""39"" ssid=""5"">They considered a semi-supervised POS tagging scenario and showed that one can use a graph over trigram types, and edge weights based on distributional similarity, to improve a supervised conditional random field tagger.</S><S sid=""42"" ssid=""8"">The foreign language vertices (denoted by Vf) correspond to foreign trigram types, exactly as in Subramanya et al. (2010).</S><S sid=""47"" ssid=""13"">Our monolingual similarity function (for connecting pairs of foreign trigram types) is the same as the one used by Subramanya et al. (2010).</S>",Method_Citation
6,P11-1061,N12-1086,0,"Das and Petrov, 2011",0,"Sparsity is desirable in settings where labeled development data for tuning thresholds that select the most probable labels for a given type is unavailable (e.g., Das and Petrov, 2011)","Sparsity is desirable in settings where labeled development data for tuning thresholds that select the most probable labels for a given type is unavailable (e.g., Das and Petrov, 2011)","'17','31','97','127'","<S sid=""17"" ssid=""13"">Second, we treat the projected labels as features in an unsupervised model (&#167;5), rather than using them directly for supervised training.</S><S sid=""31"" ssid=""8"">By aggregating the POS labels of the English tokens to types, we can generate label distributions for the English vertices.</S><S sid=""97"" ssid=""28"">This formulation of the constraint feature is equivalent to the use of a tagging dictionary extracted from the graph using a threshold T on the posterior distribution of tags for a given word type (Eq.</S><S sid=""127"" ssid=""27"">Furthermore we expect the label distributions on the foreign to be fairly noisy, because the graph constraints have not been taken into account yet.</S>",Method_Citation
7,P11-1061,N12-1052,0,2011,0,"Specifically, by replacing fine-grained language specific part-of-speech tags with universal part-of-speech tags, generated with the method described by Das and Petrov (2011), a universal parser is achieved that can be applied to any language for which universal part-of-speech tags are available. Below, we extend this approach to universal parsing by adding cross-lingual word cluster features","Specifically, by replacing fine-grained language specific part-of-speech tags with universal part-of-speech tags, generated with the method described by Das and Petrov (2011), a universal parser is achieved that can be applied to any language for which universal part-of-speech tags are available. Below, we extend this approach to universal parsing by adding cross-lingual word cluster features","'0','1','18','113'","<S sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S sid=""1"" ssid=""1"">We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language.</S><S sid=""18"" ssid=""14"">To make the projection practical, we rely on the twelve universal part-of-speech tags of Petrov et al. (2011).</S><S sid=""113"" ssid=""13"">For each language under consideration, Petrov et al. (2011) provide a mapping A from the fine-grained language specific POS tags in the foreign treebank to the universal POS tags.</S>",Method_Citation
8,P11-1061,N12-1052,0,2011,0,"We study the impact of using cross-lingual cluster features by comparing the strong delexicalized baseline model of McDonald et al (2011), which only has features derived from universal part-of-speech tags, projected from English with the method of Das and Petrov (2011), to the same model when adding features derived from cross-lingual clusters","We study the impact of using cross-lingual cluster features by comparing the strong delexicalized baseline model of McDonald et al (2011), which only has features derived from universal part-of-speech tags, projected from English with the method of Das and Petrov (2011), to the same model when adding features derived from cross-lingual clusters","'2','17','18','30'","<S sid=""2"" ssid=""2"">Our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages.</S><S sid=""17"" ssid=""13"">Second, we treat the projected labels as features in an unsupervised model (&#167;5), rather than using them directly for supervised training.</S><S sid=""18"" ssid=""14"">To make the projection practical, we rely on the twelve universal part-of-speech tags of Petrov et al. (2011).</S><S sid=""30"" ssid=""7"">To initialize the graph we tag the English side of the parallel text using a supervised model.</S>",Results_Citation
9,P11-1061,N12-1090,0,"Das and Petrov, (2011)",0,"MT-based projection has been applied to various NLP tasks, such as part of-speech tagging (e.g., Das and Petrov (2011)), mention detection (e.g., Zitouni and Florian (2008)), and sentiment analysis (e.g., Mihalcea et al (2007)) .There have been two initial attempts to apply projection to create co reference-annotated data for aresource-poor language, both of which involve projecting hand-annotated co reference data from English to Romanian via a parallel corpus","MT-based projection has been applied to various NLP tasks, such as part of-speech tagging (e.g., Das and Petrov (2011)), mention detection (e.g., Zitouni and Florian (2008)), and sentiment analysis (e.g., Mihalcea et al (2007))","'18','113','119','152'","<S sid=""18"" ssid=""14"">To make the projection practical, we rely on the twelve universal part-of-speech tags of Petrov et al. (2011).</S><S sid=""113"" ssid=""13"">For each language under consideration, Petrov et al. (2011) provide a mapping A from the fine-grained language specific POS tags in the foreign treebank to the universal POS tags.</S><S sid=""119"" ssid=""19"">To provide a thorough analysis, we evaluated three baselines and two oracles in addition to two variants of our graph-based approach.</S><S sid=""152"" ssid=""15"">6) are noisy, the results confirm that label propagation within the foreign language part of the graph adds significant quality for every language.</S>","Aim_Citation,Method_Citation"
10,P11-1061,W11-2205,0,2011,0,"For example, the multilingual PoS induction approach of Das and Petrov (2011) assumes no supervision for the language whose PoS tags are being 35 induced, but it assumes access to a labeled dataset of a different language. We begin by surveying recent work on unsupervised PoS tagging, focusing on the issue of evaluation (Section 2)","For example, the multilingual PoS induction approach of Das and Petrov (2011) assumes no supervision for the language whose PoS tags are being 35 induced, but it assumes access to a labeled dataset of a different language. We begin by surveying recent work on unsupervised PoS tagging, focusing on the issue of evaluation (Section 2)","'1','13','23','113'","<S sid=""1"" ssid=""1"">We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language.</S><S sid=""13"" ssid=""9"">(2009) study related but different multilingual grammar and tagger induction tasks, where it is assumed that no labeled data at all is available.</S><S sid=""23"" ssid=""19"">Our final average POS tagging accuracy of 83.4% compares very favorably to the average accuracy of Berg-Kirkpatrick et al.&#8217;s monolingual unsupervised state-of-the-art model (73.0%), and considerably bridges the gap to fully supervised POS tagging performance (96.6%).</S><S sid=""113"" ssid=""13"">For each language under consideration, Petrov et al. (2011) provide a mapping A from the fine-grained language specific POS tags in the foreign treebank to the universal POS tags.</S>",Method_Citation
11,P11-1061,P13-1155,0,"Das and Petrov, 2011",0,"(Das and Petrov, 2011) used graph-based label propagation for cross-lingual knowledge transfers to induce POS tags between two languages","(Das and Petrov, 2011) used graph-based label propagation for cross-lingual knowledge transfers to induce POS tags between two languages","'1','2','3','70'","<S sid=""1"" ssid=""1"">We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language.</S><S sid=""2"" ssid=""2"">Our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages.</S><S sid=""3"" ssid=""3"">We use graph-based label propagation for cross-lingual knowledge transfer and use the projected labels as features in an unsupervised model (Berg- Kirkpatrick et al., 2010).</S><S sid=""70"" ssid=""1"">Given the bilingual graph described in the previous section, we can use label propagation to project the English POS labels to the foreign language.</S>",Results_Citation
12,P11-1061,D12-1127,0,2011,0,Recent work by Das and Petrov (2011 )buildsa dictionary for a particular language by transfer ring annotated data from a resource-rich language through the use of word alignments in parallel text,Recent work by Das and Petrov (2011 ) builds a dictionary for a particular language by transferring annotated data from a resource-rich language through the use of word alignments in parallel text,"'2','24','159','160'","<S sid=""2"" ssid=""2"">Our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages.</S><S sid=""24"" ssid=""1"">The focus of this work is on building POS taggers for foreign languages, assuming that we have an English POS tagger and some parallel text between the two languages.</S><S sid=""159"" ssid=""2"">Because we are interested in applying our techniques to languages for which no labeled resources are available, we paid particular attention to minimize the number of free parameters and used the same hyperparameters for all language pairs.</S><S sid=""160"" ssid=""3"">Our results suggest that it is possible to learn accurate POS taggers for languages which do not have any annotated data, but have translations into a resource-rich language.</S>",Method_Citation
13,P11-1061,D12-1127,0,"Das and Petrov, 2011",0,"Theseapproaches build a dictionary by transferring labeled data from a resource rich language (English) to a re source poor language (Das and Petrov, 2011)","These approaches build a dictionary by transferring labeled data from a resource rich language (English) to a resource poor language (Das and Petrov, 2011)","'1','2','17','107'","<S sid=""1"" ssid=""1"">We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language.</S><S sid=""2"" ssid=""2"">Our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages.</S><S sid=""17"" ssid=""13"">Second, we treat the projected labels as features in an unsupervised model (&#167;5), rather than using them directly for supervised training.</S><S sid=""107"" ssid=""7"">Of course, we are primarily interested in applying our techniques to languages for which no labeled resources are available.</S>",Results_Citation
14,P11-1061,P12-3012,0,"Das and Petrov, 2011",0,"In recent years research in Natural Language Processing (NLP) has been steadily moving towards multilingual processing: the availability of ever growing amounts of text in different languages ,infact, has been a major driving force behind research on multilingual approaches, from morphosyntactic (Das and Petrov, 2011) and syntactico semantic (Peirsman and Pado?, 2010) phenomena to high-end tasks like textual entailment (Mehdad et al., 2011) and sentiment analysis (Lu et al, 2011)","In recent years research in Natural Language Processing (NLP) has been steadily moving towards multilingual processing: the availability of ever growing amounts of text in different languages, in fact, has been a major driving force behind research on multilingual approaches, from morphosyntactic (Das and Petrov, 2011) and syntactico semantic (Peirsman and Pado?, 2010) phenomena to high-end tasks like textual entailment (Mehdad et al., 2011) and sentiment analysis (Lu et al, 2011)","'2','5','10','113'","<S sid=""2"" ssid=""2"">Our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages.</S><S sid=""5"" ssid=""1"">Supervised learning approaches have advanced the state-of-the-art on a variety of tasks in natural language processing, resulting in highly accurate systems.</S><S sid=""10"" ssid=""6"">To bridge this gap, we consider a practically motivated scenario, in which we want to leverage existing resources from a resource-rich language (like English) when building tools for resource-poor foreign languages.1 We assume that absolutely no labeled training data is available for the foreign language of interest, but that we have access to parallel data with a resource-rich language.</S><S sid=""113"" ssid=""13"">For each language under consideration, Petrov et al. (2011) provide a mapping A from the fine-grained language specific POS tags in the foreign treebank to the universal POS tags.</S>",Method_Citation
15,P11-1061,D11-1006,0,2011,0,"Furthermore, we evaluate with both gold-standard part-of-speech tags, as well as predicted part-of speech tags from the projected part-of-speech tagger of Das and Petrov (2011) .2 This tagger relies only onlabeled training data for English, and achieves accuracies around 85% on the languages that we con sider","Furthermore, we evaluate with both gold-standard part-of-speech tags, as well as predicted part-of speech tags from the projected part-of-speech tagger of Das and Petrov (2011). This tagger relies only on labeled training data for English, and achieves accuracies around 85% on the languages that we consider","'0','1','18','69'","<S sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S sid=""1"" ssid=""1"">We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language.</S><S sid=""18"" ssid=""14"">To make the projection practical, we rely on the twelve universal part-of-speech tags of Petrov et al. (2011).</S><S sid=""69"" ssid=""35"">Label propagation is used to propagate these tags inwards and results in tag distributions for the middle word of each Italian trigram.</S>",Method_Citation
16,P11-1061,D11-1006,0,2011,0,"In the first, we assumed that the test set for each target language had gold part-of-speech tags, and in the second we used predicted part-of-speech tags from the projection tagger of Das and Petrov (2011), which also uses English as the source language","In the first, we assumed that the test set for each target language had gold part-of-speech tags, and in the second we used predicted part-of-speech tags from the projection tagger of Das and Petrov (2011), which also uses English as the source language","'1','17','18','24'","<S sid=""1"" ssid=""1"">We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language.</S><S sid=""17"" ssid=""13"">Second, we treat the projected labels as features in an unsupervised model (&#167;5), rather than using them directly for supervised training.</S><S sid=""18"" ssid=""14"">To make the projection practical, we rely on the twelve universal part-of-speech tags of Petrov et al. (2011).</S><S sid=""24"" ssid=""1"">The focus of this work is on building POS taggers for foreign languages, assuming that we have an English POS tagger and some parallel text between the two languages.</S>",Results_Citation
17,P11-1061,P13-2112,0,2011,0,"This parallel data can be exploited to bridge languages, and in particular, transfer information from a highly-resourced language to a lesser-resourced language, to build unsupervised POS taggers. In this paper, we propose an unsupervised approach to POS tagging in a similar vein to the work of Das and Petrov (2011)","This parallel data can be exploited to bridge languages, and in particular, transfer information from a highly-resourced language to a lesser-resourced language, to build unsupervised POS taggers. In this paper, we propose an unsupervised approach to POS tagging in a similar vein to the work of Das and Petrov (2011)","'1','2','24','120'","<S sid=""1"" ssid=""1"">We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language.</S><S sid=""2"" ssid=""2"">Our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages.</S><S sid=""24"" ssid=""1"">The focus of this work is on building POS taggers for foreign languages, assuming that we have an English POS tagger and some parallel text between the two languages.</S><S sid=""120"" ssid=""20"">We were intentionally lenient with our baselines: bilingual information by projecting POS tags directly across alignments in the parallel data.</S>",Method_Citation
18,P11-1061,P13-2112,0,2011,0,Das and Petrov (2011) achieved the current state-of-the-art for unsupervised tagging by exploiting high confidence alignments to copy tags from the source language to the target language,Das and Petrov (2011) achieved the current state-of-the-art for unsupervised tagging by exploiting high confidence alignments to copy tags from the source language to the target language,"'1','18','113','144'","<S sid=""1"" ssid=""1"">We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language.</S><S sid=""18"" ssid=""14"">To make the projection practical, we rely on the twelve universal part-of-speech tags of Petrov et al. (2011).</S><S sid=""113"" ssid=""13"">For each language under consideration, Petrov et al. (2011) provide a mapping A from the fine-grained language specific POS tags in the foreign treebank to the universal POS tags.</S><S sid=""144"" ssid=""7"">For comparison, the completely unsupervised feature-HMM baseline accuracy on the universal POS tags for English is 79.4%, and goes up to 88.7% with a treebank dictionary.</S>",Results_Citation
19,P11-1061,P13-2112,0,"Das and Petrov, 2011",0,"We have proposed a method for unsupervised POStagging that performs on par with the current state of-the-art (Das and Petrov, 2011), but is subs tan tially less-sophisticated (specifically not requiring convex optimization or a feature-based HMM)","We have proposed a method for unsupervised POS tagging that performs on par with the current state of-the-art (Das and Petrov, 2011), but is substantially less-sophisticated (specifically not requiring convex optimization or a feature-based HMM)","'1','93','94','113'","<S sid=""1"" ssid=""1"">We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language.</S><S sid=""93"" ssid=""24"">For English POS tagging, BergKirkpatrick et al. (2010) found that this direct gradient method performed better (&gt;7% absolute accuracy) than using a feature-enhanced modification of the Expectation-Maximization (EM) algorithm (Dempster et al., 1977).8 Moreover, this route of optimization outperformed a vanilla HMM trained with EM by 12%.</S><S sid=""94"" ssid=""25"">We adopted this state-of-the-art model because it makes it easy to experiment with various ways of incorporating our novel constraint feature into the log-linear emission model.</S><S sid=""113"" ssid=""13"">For each language under consideration, Petrov et al. (2011) provide a mapping A from the fine-grained language specific POS tags in the foreign treebank to the universal POS tags.</S>",Results_Citation
