S sid="6" ssid="4">In this paper, we report adapting a lexicalized, probabilistic context-free parser with head rules (LPCFG-HR) to information extraction.</S> Our integrated model represents syntax and semantics jointly using augmented parse trees. In these trees, the standard TREEBANK structures are augmented to convey semantic information, that is, entities and relations. By necessity, we adopted the strategy of hand marking only the semantics. Figure 4 shows an example of the semantic annotation, which was the only type of manual annotation we performed. Instead, our parsing algorithm, trained on the UPenn TREEBANK, was run on the New York Times source to create unsupervised syntactic training which was constrained to be consistent with semantic annotation.</S For the following example, the The Template Relations (TR) task involves identifying instances of three relations in the text: TR builds on TE in that TR reports binary relations between elements of TE. An integrated model can limit the propagation of errors by making all decisions jointly. For this reason, we focused on designing an integrated model in which tagging, namefinding, parsing, and semantic interpretation decisions all have the opportunity to mutually influence each other. An integrated model can limit the propagation of errors by making all decisions jointly. For this reason, we focused on designing an integrated model in which tagging, namefinding, parsing, and semantic interpretation decisions all have the opportunity to mutually influence each other. In these trees, the standard TREEBANK structures are augmented to convey semantic information, that is, entities and relations. "S sid=""60"" ssid=""1"">In our statistical model, trees are generated according to a process similar to that described in (Collins 1996, 1997).</S> The detailed probability structure differs, however, in that it was designed to jointly perform part-of-speech tagging, name finding, syntactic parsing, and relation finding in a single process. Our integrated model represents syntax and semantics jointly using augmented parse trees. We evaluated the new approach to information extraction on two of the tasks of the Seventh Message Understanding Conference (MUC-7) and reported in (Marsh, 1998). The Template Element (TE) task identifies organizations, persons, locations, and some artifacts (rocket and airplane-related artifacts). A single model proved capable of performing all necessary sentential processing, both syntactic and semantic. In our statistical model, trees are generated according to a process similar to that described in (Collins 1996, 1997). The detailed probability structure differs, however, in that it was designed to jointly perform part-of-speech tagging, name finding, syntactic parsing, and relation finding in a single process.
