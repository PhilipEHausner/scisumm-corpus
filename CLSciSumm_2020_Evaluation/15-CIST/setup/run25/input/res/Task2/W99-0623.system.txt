Three state-of-the-art statistical parsers are combined to produce more accurate parses, as well as new bounds on achievable Treebank parsing accuracy. We then show that the combining techniques presented above give better parsing accuracy than any of the individual parsers. Finally we show the combining techniques degrade very little when a poor parser is added to the set. It is possible one could produce better models by introducing features describing constituents and their contexts because one parser could be much better than the majority of the others in particular situations. We call this technique constituent voting. IL+-1Proof: Assume a pair of crossing constituents appears in the output of the constituent voting technique using k parsers. In the cases where isolated constituent precision is larger than 0.5 the affected portion of the hypotheses is negligible. Similarly Figures 1 and 2 show how the isolated constituent precision varies by sentence length and the size of the span of the hypothesized constituent. We used these three parsers to explore parser combination techniques. Another technique for parse hybridization is to use a na&#239;ve Bayes classifier to determine which constituents to include in the parse. Mi(c) is a binary function returning t when parser i (from among the k parsers) suggests constituent c should be in the parse. If we were working with more than three parsers we could investigate minority constituents, those constituents that are suggested by at least one parser, but which the majority of the parsers do not suggest. If enough parsers