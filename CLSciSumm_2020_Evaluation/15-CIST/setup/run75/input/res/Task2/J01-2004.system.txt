A second key feature of our approach is that top-down guidance improves the efficiency of the search as more and more conditioning events are extracted from the derivation for use in the probabilistic model . The leftfactorization transform that we use is identical to what is called right binarization in Roark and Johnson ( 1999 ) . The parsers with the highest published broad-coverage parsing accuracy , which include Charniak ( 1997 , 2000 ) , Collins ( 1997 , 1999 ) , and Ratnaparkhi ( 1997 ) , all utilize simple and straightforward statistically based search heuristics , pruning the search-space quite dramatically ! \ . Let Ht be the priority queue H , before any processing has begun with word w , in the look-ahead . These can be divided into two rough groups : those that use the grammar as a language model , and those that use a parser to uncover phrasal heads standing in an important relation ( c-command ) to the current word . A lexicalized probabilistic topdown parser is then presented , which performs very well , in terms of both the accuracy of returned parses and the efficiency with which they are found , relative to the best broad-coverage statistical parsers . In addition , as mentioned above , we would like to further test our language model in speech recognition tasks , to see if the perplexity improvement that we have seen can lead to significant reductions in word error rate