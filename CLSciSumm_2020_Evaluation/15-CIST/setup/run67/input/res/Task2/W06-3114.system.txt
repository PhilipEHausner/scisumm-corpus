Confidence Interval: Since BLEU scores are not computed on the sentence level, traditional methods to compute statistical significance and confidence intervals do not apply. Hence, we use the bootstrap resampling method described by Koehn (2004). The bootstrap method has been critized by Riezler and Maxwell (2005) and Collins et al. (2005), as being too optimistic in deciding for statistical significant difference between systems. We are therefore applying a different method, which has been used at the 2005 DARPA/NIST evaluation. We dropped, however, one of the languages, Finnish, partly to keep the number of tracks manageable, partly because we assumed that it would be hard to find enough Finnish speakers for the manual evaluation. Most of these groups follow a phrase-based statistical approach to machine translation. The other half was replaced by other participants, so we ended up with roughly the same number. The main disadvantage of manual evaluation is that it is time-consuming and thus too expensive to do frequently. Training and testing is based on the Europarl corpus. We are currently working on a complete open source implementation of a training and decoding system, which should become available over the summer. pus, from which also the in-domain test set is taken. Out-of-domain test data is from the Project Syndicate web site, a compendium of political commentary. In addition to the Europarl test set, we also collected 29 editorials from the Project Syndicate website2, which are published in all the four languages of the shared task. The BLEU score has