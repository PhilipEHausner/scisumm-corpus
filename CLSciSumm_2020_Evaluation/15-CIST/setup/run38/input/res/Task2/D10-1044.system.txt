955 ; ( s , t ) : To motivate weighting joint OUT counts as in ( 6 ) , we begin with the & This is less effective in our setting , where IN and OUT are disparate . This is less effective in our setting , where IN and OUT are disparate . Linear weights are difficult to incorporate into the standard MERT procedure because they are & 955 ; ( s , t ) : To motivate weighting joint OUT counts as in ( 6 ) , we begin with the & Discriminative Instance Weighting for Domain Adaptation in Statistical Machine Translatio . This is a standard adaptation problem for SMT . In addition to using the simple features directly , we also trained an SVM classifier with these features to distinguish between IN and OUT phrase pairs . First , we learn weights on individual phrase pairs rather than sentences . The corpora for both settings are summarized in table 1 . We train linear mixture models for conditional phrase pair probabilities over IN and OUT so as to maximize the likelihood of an empirical joint phrase-pair distribution extracted from a development set . Mixing , smoothing , and instance-feature weights are learned at the same time using an efficient maximum-likelihood procedure that relies on only a small in-domain development corpus . This best instance-weighting model beats the equivalant model without instance weights by between 0.6 BLEU and 1.8 BLEU , and beats the log-linear baseline