Discriminative Instance Weighting for Domain Adaptation in Statistical Machine Translatio. ), which precludes a single universal approach to adaptation. This is a standard adaptation problem for SMT. There is a fairly large body of work on SMT adaptation. We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain, determined by both how similar to it they appear to be, and whether they belong to general language or not. Matsoukas et al (2009) generalize it by learning weights on sentence pairs that are used when estimating relative-frequency phrase-pair probabilities. First, we learn weights on individual phrase pairs rather than sentences. In future work we plan to try this approach with more competitive SMT systems, and to extend instance weighting to other standard SMT components such as the LM, lexical phrase weights, and lexicalized distortion. Domain adaptation is a common concern when optimizing empirical NLP applications. Even when there is training data available in the domain of interest, there is often additional data from other domains that could in principle be used to improve performance. There has also been some work on adapting the word alignment model prior to phrase extraction (Civera and Juan, 2007; Wu et al., 2005), and on dynamically choosing a dev set (Xu et al., 2007). Sentence pairs are the natural instances for SMT, but sentences often contain a mix of domain-specific and general language. For comparison to information-retrieval inspired baselines, eg (L&#168;u et al., 2007), we