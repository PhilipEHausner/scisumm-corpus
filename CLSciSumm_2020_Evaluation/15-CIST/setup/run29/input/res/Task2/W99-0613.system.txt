A contextual rule considers words surrounding the string in the sentence in which it appears ( e.g. , a rule that any proper name modified by an appositive whose head is president is a person ) . The numbers falling into the location , person , organization categories were 186 , 289 and 402 respectively . There are two differences between this method and the DL-CoTrain algorithm : spelling and contextual features , alternating between labeling and learning with the two types of features . ( Blum and Mitchell 98 ) offer a promising formulation of redundancy , also prove some results about how the use of unlabeled examples can help classification , and suggest an objective function when training with unlabeled examples . AdaBoost was first introduced in ( Freund and Schapire 97 ) ; ( Schapire and Singer 98 ) gave a generalization of AdaBoost which we will use in this paper . This paper discusses the use of unlabeled examples for the problem of named entity classification . The approach gains leverage from natural redundancy in the data : for many named-entity instances both the spelling of the name and the context in which it appears are sufficient to determine its type . contains ( York ) and is never seen with a feature such as contains ( Group ) ) . Many statistical or machine-learning approaches for natural language problems require a relatively large amount of supervision , in the form of labeled training examples .