The probability of a parse tree T is the sum of the probabilities of its distinct derivations. This means that summing up over derivations of a tree in DOP yields the same probability as summing over all the isomorphic derivations in the PCFG. Note that Goodman\'s reduction method does still not allow for an efficient computation of the most probable parse tree of a sentence: there may still be exponentially many derivations generating the same tree. The derivation with the smallest sum, or highest rank, is taken as the final best derivation producing the best parse tree in Simplicity-DOP.3 Although Bod (2000b) reports that Simplicity DOP is outperformed by Likelihood-DOP, its results are still rather impressive for such a simple model. Although Bod\'s method obtains very competitive results on the Wall Street Journal (WSJ) task, the parsing time was reported to be over 200 seconds per sentence (Bod 2003). But while Bod\'s estimator obtains state-of-the-art results on the WSJ, comparable to Charniak (2000) and Collins (2000), Bonnema et al. \'s estimator performs worse and is comparable to Collins (1996). While the PCFG reduction of Bod (2001) obtains state-of-the-art results on the WSJ, comparable to Charniak (2000), Bonnema et al. \'s estimator performs worse and is comparable to Collins (1996). Bod (2001) used an alternative technique which samples a fixed number of subtrees of each depth and which has the effect of assigning roughly equal weight to each node in the training data. Collins &amp; Duffy (2002) showed how the perceptron