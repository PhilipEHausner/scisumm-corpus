In this section , we describe the algorithm that was used to automatically produce augmented trees , starting with a ) human-generated semantic annotations and b ) machinegenerated syntactic parse trees . To produce a corpus of augmented parse trees , we used the following multi-step training procedure which exploited the Penn TREEBANK Applying this procedure yielded a new version of the semantically annotated corpus , now annotated with complete augmented trees like that in Figure 3 . Maximum likelihood estimates for the model probabilities can be obtained by observing frequencies in the training corpus . The semantics & The Template Element ( TE ) task identifies organizations , persons , locations , and some artifacts ( rocket and airplane-related artifacts ) . Given a new sentence , the outcome of this search process is a tree structure that encodes both the syntactic and semantic structure of the sentence . Maximum likelihood estimates for the model probabilities can be obtained by observing frequencies in the training corpus . 8212 ; especially their ability to learn from large amounts of data , and their robustness when presented with unexpected inputs & The Template Element ( TE ) task identifies organizations , persons , locations , and some artifacts ( rocket and airplane-related artifacts ) . We have demonstrated , at least for one problem , that a lexicalized , probabilistic context-free parser with head rules ( LPCFGHR ) can be used effectively for information extraction . Finally , our newly constructed