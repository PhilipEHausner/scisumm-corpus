We evaluated the new approach to information extraction on two of the tasks of the Seventh Message Understanding Conference (MUC-7) and reported in (Marsh, 1998). In this section, we describe the algorithm that was used to automatically produce augmented trees, starting with a) human-generated semantic annotations and b) machinegenerated syntactic parse trees. Figure 4 shows an example of the semantic annotation, which was the only type of manual annotation we performed. In these trees, the standard TREEBANK structures are augmented to convey semantic information, that is, entities and relations. We were able to use the Penn TREEBANK to estimate the syntactic parameters; no additional syntactic training was required. In this paper, we report adapting a lexicalized, probabilistic context-free parser with head rules (LPCFG-HR) to information extraction. The Template Element (TE) task identifies organizations, persons, locations, and some artifacts (rocket and airplane-related artifacts). Since 1995, a few statistical parsing algorithms (Magerman, 1995; Collins, 1996 and 1997; Charniak, 1997; Rathnaparki, 1997) demonstrated a breakthrough in parsing accuracy, as measured against the University of Pennsylvania TREEBANK as a gold standard. Because generative statistical models had already proven successful for each of the first three stages, we were optimistic that some of their properties &#8212; especially their ability to learn from large amounts of data, and their robustness when presented with unexpected inputs &#8212; would also benefit semantic analysis. Instead, our parsing algorithm, trained on the UPenn TREEBANK, was run on the New York Times source to create unsupervised syntactic training which was constrained to be consistent with semantic annotation. Given a new sentence, the outcome of this search process is a tree structure that encodes both the syntactic and semantic structure of the sentence. In this paper, we report adapting a lexicalized, probabilistic context-free parser with head rules (LPCFG-HR) to information extraction. We have demonstrated, at least for one problem, that a lexicalized, probabilistic context-free parser with head rules (LPCFGHR) can be used effectively for information extraction. We were already using a generative statistical model for part-of-speech tagging (Weischedel et al. 1993), and more recently, had begun using a generative statistical model for name finding (Bikel et al. Currently, the prevailing architecture for dividing sentential processing is a four-stage pipeline consisting of: Since we were interested in exploiting recent advances in parsing, replacing the syntactic analysis stage of the standard pipeline with a modern statistical parser was an obvious possibility.
