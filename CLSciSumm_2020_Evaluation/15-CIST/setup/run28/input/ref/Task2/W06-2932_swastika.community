Unlabeled accuracy for all verbs increases from 71% to 73% and for all conjunctions from 71% to 74%. Although overall unlabeled accuracy is 86%, most verbs and some conjunctions attach to their head words with much lower accuracy: 69% for main verbs, 75% for the verb ser, and 65% for coordinating conjunctions. An exact projective and an approximate non-projective parsing algorithm are presented, since it is shown that nonprojective dependency parsing becomes NP-hard when features are extended beyond a single edge. Based on performance from a held-out section of the training data, we used non-projective parsing algorithms for Czech, Danish, Dutch, German, Japanese, Portuguese and Slovene, and projective parsing algorithms for Arabic, Bulgarian, Chinese, Spanish, Swedish and Turkish. In this paper we describe a two-stage discriminative parsing approach consisting of an unlabeled parser and a subsequent edge labeler. An exact projective and an approximate non-projective parsing algorithm are presented, since it is shown that nonprojective dependency parsing becomes NP-hard when features are extended beyond a single edge. To model this we treat the labeling of the edges (i, j1), ... , (i, jM) as a sequence labeling problem, We use a first-order Markov factorization of the score s(l(i,jm), l(i,jm&#65533;1), i, y, x) in which each factor is the score of labeling the adjacent edges (i, jm) and (i, jm&#8722;1) in the tree y. Its power lies in the ability to define a rich set of features over parsing decisions, as well as surface level features relative to these decisions. For score functions, we use simple dot products between high dimensional feature representations and a weight vector Assuming we have an appropriate feature representation, we can find the highest scoring label sequence with Viterbi&#8217;s algorithm.
