for the perplexity and translation tasks we used srilm to build a gram english language model on million tokens from europarl v koehn and the workshop on machine translation news crawl corpus with duplicate lines removed 
time for moses itself to load including loading the language model and phrase table is included 
irstlm federico et al is an open source toolkit for building and querying language models 
performance improvements transfer to the moses koehn et al cdec dyer et al and joshua li et al translation systems where our code has been integrated 
queries detect the invalid probability using the node only if it leads to a longer match 
language models are widely applied in natural language processing and applications such as machine translation make very frequent queries 
while sorted arrays could be used to implement the same data structure as probing effectively making m we abandoned this implementation because it is slower and larger than a trie implementation 
for example syntactic decoders koehn et al dyer et al li et al perform dynamic programming parametrized by both backward and forward looking state 
with a good hash function collisions of the full bit hash are exceedingly rare one in billion queries for our baseline model will falsely find a key not present 
we present kenlm a library that implements two data structures for efficient language model queries reducing both time and costs 
unlike germann et al we chose a model size so that all benchmarks fit comfortably in main memory 
