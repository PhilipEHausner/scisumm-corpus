second, we treat the projected labels as features in an unsupervised model (ยง5), rather than using them directly for supervised training.
the supervised pos tagging accuracies (on this tagset) are shown in the last row of table 2.
unfortunately, the best completely unsupervised english pos tagger (that does not make use of a tagging dictionary) reaches only 76.1% accuracy (christodoulopoulos et al., 2010), making its practical usability questionable at best.
our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages.
to bridge this gap, we consider a practically motivated scenario, in which we want to leverage existing resources from a resource-rich language (like english) when building tools for resource-poor foreign languages.1 we assume that absolutely no labeled training data is available for the foreign language of interest, but that we have access to parallel data with a resource-rich language.
graph construction for structured prediction problems such as pos tagging is non-trivial: on the one hand, using individual words as the vertices throws away the context necessary for disambiguation; on the other hand, it is unclear how to define (sequence) similarity if the vertices correspond to entire sentences.
based on these high-confidence alignments we can extract tuples of the form [u h v], where u is a foreign trigram type, whose middle word aligns to an english word type v. our bilingual similarity function then sets the edge weights in proportion to these tuple counts.
the focus of this work is on building pos taggers for foreign languages, assuming that we have an english pos tagger and some parallel text between the two languages.
