second, we treat the projected labels as features in an unsupervised model (ยง5), rather than using them directly for supervised training.
altun et al. (2005) proposed a technique that uses graph based similarity between labeled and unlabeled parts of structured data in a discriminative framework for semi-supervised learning.
as discussed in more detail in ยง3, we use two types of vertices in our graph: on the foreign language side vertices correspond to trigram types, while the vertices on the english side are individual word types.
furthermore, we do not connect the english vertices to each other, but only to foreign language vertices.4 the graph vertices are extracted from the different sides of a parallel corpus (de, df) and an additional unlabeled monolingual foreign corpus ff, which will be used later for training.
we tried two versions of our graph-based approach: feature after the first stage of label propagation (eq.
the foreign language vertices (denoted by vf) correspond to foreign trigram types, exactly as in subramanya et al. (2010).
because many foreign word types are not aligned to an english word (see table 3), and we do not run label propagation on the foreign side, we expect the projected information to have less coverage.
for each language under consideration, petrov et al. (2011) provide a mapping a from the fine-grained language specific pos tags in the foreign treebank to the universal pos tags.
in the label propagation stage, we propagate the automatic english tags to the aligned italian trigram types, followed by further propagation solely among the italian vertices. the italian vertices are connected to an automatically labeled english vertex.
