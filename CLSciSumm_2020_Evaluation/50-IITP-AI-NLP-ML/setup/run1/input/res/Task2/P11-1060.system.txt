feedback from the context; for example, the lexical entry for borders world has been used to guide both syntactic parsing is s\np/np : ay.ax.border(x, y), which means (schuler, 2003) and semantic parsing (popescu et borders looks right for the first argument and left al., 2003; clarke et al., 2010).
trace inspired by discourse representation theory (drt) predicates can be inserted anywhere, but the fea- (kamp and reyle, 1993; kamp et al., 2005), where tures favor some insertions depending on the words variables are discourse referents.
as in clarke et al. (2010), we obviate the need for annotated logical forms by considering the endto-end problem of mapping questions to answers.
results we first compare our system with clarke et al. (2010) (henceforth, semresp), which also learns a semantic parser from question-answer pairs.
our employed (zettlemoyer and collins, 2007) or words work pushes the grounded language agenda towards are given multiple lexical entries (kwiatkowski et deeper representations of language—think grounded al., 2010). compositional semantics.
these rules are often too stringent, cused on aligning text to a world (liang et al., 2009), and for complex utterances, especially in free word- using text in reinforcement learning (branavan et al., order languages, either disharmonic combinators are 2009; branavan et al., 2010), and many others.
to further reduce the search space, f imposes a few additional constraints, e.g., limiting the number of marked nodes to 2 and only allowing trace predicates between arity 1 predicates.
it is impossible to represent the semantics of this phrase with just a csp, so we introduce a new aggregate relation, notated e. consider a tree he:ci, whose root is connected to a child c via e. if the denotation of c is a set of values s, the parent’s denotation is then a singleton set containing s. formally: figure 3(a) shows the dcs tree for our running example.
