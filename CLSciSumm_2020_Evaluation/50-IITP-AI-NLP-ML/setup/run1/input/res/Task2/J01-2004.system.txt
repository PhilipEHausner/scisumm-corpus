also, the parser returns a set of candidate parses, from which we have been choosing the top ranked; if we use an oracle to choose the parse with the highest accuracy from among the candidates (which averaged 70.0 in number per sentence), we find an average labeled precision/recall of 94.1, for sentences of length < 100.
this contrasts with our perplexity results reported above, as well as with the recognition experiments in chelba (2000), where the best results resulted from interpolated models.
he was able to reduce both sentence and word error rates on the atis corpus using this method.
by including these nodes (which are in the original annotation of the penn treebank), we may be able to bring certain long-distance dependencies into a local focus.
however, when we interpolate with the trigram, we see that the additional improvement is greater than the one they experienced.
in addition, as mentioned above, we would like to further test our language model in speech recognition tasks, to see if the perplexity improvement that we have seen can lead to significant reductions in word error rate.
these perplexity improvements are particularly promising, because the parser is providing information that is, in some sense, orthogonal to the information provided by a trigram model, as evidenced by the robust improvements to the baseline trigram when the two models are interpolated.
in the event that no complete parse is found, the highest initially ranked parse on the last nonempty priority queue is returned.
thus, our top-down parser allows for the incremental calculation of generative conditional word probabilities, a property it shares with other left-to-right parsers with rooted derivations such as earley parsers (earley 1970) or left-corner parsers (rosenkrantz and lewis 11 1970).
