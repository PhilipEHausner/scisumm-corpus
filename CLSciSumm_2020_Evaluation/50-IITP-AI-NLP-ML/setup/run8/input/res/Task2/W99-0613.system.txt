the following features were used: full-string=x the full string (e.g., for maury cooper, full- s tring=maury_cooper). contains(x) if the spelling contains more than one word, this feature applies for any words that the string contains (e.g., maury cooper contributes two such features, contains (maury) and contains (cooper) . allcapl this feature appears if the spelling is a single word which is all capitals (e.g., ibm would contribute this feature). allcap2 this feature appears if the spelling is a single word which is all capitals or full periods, and contains at least one period.
when this feature type was included, coboost chose this default feature at an early iteration, thereby giving non-abstaining pseudo-labels for all examples, with eventual convergence to the two classifiers agreeing by assigning the same label to almost all examples.
several extensions of adaboost for multiclass problems have been suggested (freund and schapire 97; schapire and singer 98).
it may be more realistic to replace the second criteria with a softer one, for example (blum and mitchell 98) suggest the alternative alternatively, if ii and 12 are probabilistic learners, it might make sense to encode the second constraint as one of minimizing some measure of the distance between the distributions given by the two learners.
recent results (e.g., (yarowsky 95; brill 95; blum and mitchell 98)) have suggested that unlabeled data can be used quite profitably in reducing the need for supervision.
971,746 sentences of new york times text were parsed using the parser of (collins 96).1 word sequences that met the following criteria were then extracted as named entity examples: whose head is a singular noun (tagged nn).
