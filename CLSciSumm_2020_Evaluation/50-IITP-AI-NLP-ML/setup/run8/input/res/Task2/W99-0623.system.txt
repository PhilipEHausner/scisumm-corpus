the three parsers were trained and tuned by their creators on various sections of the wsj portion of the penn treebank, leaving only sections 22 and 23 completely untouched during the development of any of the parsers.
the development of a naïve bayes classifier involves learning how much each parser should be trusted for the decisions it makes.
furthermore, we know one of the original parses will be the hypothesized parse, so the direct method of determining which one is best is to compute the probability of each of the candidate parses using the probabilistic model we developed in section 2.1.
none of the models we have presented utilize features associated with a particular constituent (i.e. the label, span, parent label, etc.) to influence parser preference.
it is the performance we could achieve if an omniscient observer told us which parser to pick for each of the sentences.
the corpus-based statistical parsing community has many fast and accurate automated parsing systems, including systems produced by collins (1997), charniak (1997) and ratnaparkhi (1997).
in equations 1 through 3 we develop the model for constructing our parse using naïve bayes classification.
adding the isolated constituents to our hypothesis parse could increase our expected recall, but in the cases we investigated it would invariably hurt our precision more than we would gain on recall.
recently, combination techniques have been investigated for part of speech tagging with positive results (van halteren et al., 1998; brill and wu, 1998).
similar advances have been made in machine translation (frederking and nirenburg, 1994), speech recognition (fiscus, 1997) and named entity recognition (borthwick et al., 1998).
