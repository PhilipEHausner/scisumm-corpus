in this paper we report adapting a lexicalized probabilistic context free parser with head rules lpcfg hr to information extraction 
given multiple constituents that cover identical spans in the chart only those constituents with probabilities within a while our focus throughout the project was on te and tr we became curious about how well the model did at part of speech tagging syntactic parsing and at name finding 
chiba was able to use such a parsing algorithm to reduce perplexity with the long term goal of improved speech recognition 
there is no opportunity for a later stage such as parsing to influence or correct an earlier stage such as part of speech tagging 
for the following example the template relation in figure was to be generated quot donald m goldstein a historian at the university of pittsburgh who helped write quot 
in this paper we report adapting a lexic al ized probabilistic context free parser to information extraction and evaluate this new technique on muc template elements and template relations 
whenever two or more constituents are equivalent relative to all possible later parsing decisions we apply dynamic programming keeping only the most likely constituent in the chart 
currently the prevailing architecture for dividing sentential processing is a four stage pipeline consisting of since we were interested in exploiting recent advances in parsing replacing the syntactic analysis stage of the standard pipeline with a modern statistical parser was an obvious possibility 
for example an error made during part of speech tagging may cause a future error in syntactic analysis which may in turn cause a semantic interpretation failure 
