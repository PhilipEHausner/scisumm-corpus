the main technical contribution of this work is a new semantic representation, dependency-based compositional semantics (dcs), which is both simple and expressive (section 2).
we first present a basic version (section 2.1) of dependency-based compositional semantics (dcs), which captures the core idea of using trees to represent formal semantics.
these rules are often too stringent, cused on aligning text to a world (liang et al., 2009), and for complex utterances, especially in free word- using text in reinforcement learning (branavan et al., order languages, either disharmonic combinators are 2009; branavan et al., 2010), and many others.
it is impossible to represent the semantics of this phrase with just a csp, so we introduce a new aggregate relation, notated e. consider a tree he:ci, whose root is connected to a child c via e. if the denotation of c is a set of values s, the parent’s denotation is then a singleton set containing s. formally: figure 3(a) shows the dcs tree for our running example.
ccg is one instantiation (steedman, 2000), which is used by many semantic parsers, e.g., zettlemoyer and collins (2005).
eisenciations due to data sparsity, and having an insuffi- stein et al. (2009) induces conjunctive formulae and ciently large k. uses them as features in another learning problem.
our employed (zettlemoyer and collins, 2007) or words work pushes the grounded language agenda towards are given multiple lexical entries (kwiatkowski et deeper representations of language—think grounded al., 2010). compositional semantics.
unlike standard semantic parsing, our end goal is only to generate the correct y, so we are free to choose the representation for z.
