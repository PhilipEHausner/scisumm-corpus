however, the parser is fundamentally limited by the scope of local factorizations that make inference tractable.
furthermore, for arabic and spanish, we used lemmas instead of inflected word forms, again based on performance on held-out data1.
dependency graphs also encode much of the deep syntactic information needed for further processing.
in fact, for every language our models perform significantly higher than the average performance for all the systems reported in buchholz et al. (2006).
the first stage based on the unlabeled dependency parsing models described by mcdonald and pereira (2006) augmented with morphological features for a subset of the languages.
these weaknesses are not surprising, since these decisions encode the more global aspects of sentence structure: arrangement of clauses and adverbial dependents in multi-clause sentences, and prepositional phrase attachment.
that work extends the maximum spanning tree dependency parsing framework (mcdonald et al., 2005a; mcdonald et al., 2005b) to incorporate features over multiple edges in the dependency graph.
these results show that the discriminative spanning tree parsing framework (mcdonald et al., 2005b; mcdonald and pereira, 2006) is easily adapted across all these languages.
we have presented results showing that the spanning tree dependency parsing framework of mcdonald et al. (mcdonald et al., 2005b; mcdonald and pereira, 2006) generalizes well to languages other than english.
the second stage takes the output from the first and labels all the edges in the dependency graph with appropriate syntactic categories using a globally trained sequence classifier over components of the graph.
this system is primarily based on the parsing models described by mcdonald and pereira (2006).
