in this paper, we present the polylingual topic model (pltm).
outside of the field of topic modeling, kawaba et al. (kawaba et al., 2008) use a wikipedia-based model to perform sentiment analysis of blog posts.
an important application for polylingual topic modeling is to use small numbers of comparable document tuples to link topics in larger collections of distinct, non-comparable documents in multiple languages.
in finding a lowdimensional semantic representation, topic models deliberately smooth over much of the variation present in language.
topic models have been used for analyzing topic trends in research literature (mann et al., 2006; hall et al., 2008), inferring captions for images (blei and jordan, 2003), social network analysis in email (mccallum et al., 2005), and expanding queries with topically related words in information retrieval (wei and croft, 2006).
one simple way to achieve this topic alignment is to add a small set of comparable document tuples that provide sufficient “glue” to bind the topics together.
we introduced a polylingual topic model (pltm) that discovers topics aligned across multiple languages.
a recent extended abstract, developed concurrently by ni et al. (ni et al., 2009), discusses a multilingual topic model similar to the one presented here.
we argue that topic modeling is both a useful and appropriate tool for leveraging correspondences between semantically comparable documents in multiple different languages.
we introduce a polylingual topic model that discovers topics aligned across multiple languages.
we also demonstrated that relatively small numbers of topically comparable document tuples are sufficient to align topics between languages in non-comparable corpora.
they also provide little analysis of the differences between polylingual and single-language topic models.
