little attention, however, has been paid to the structural descriptions that these formalisms can assign to strings, i.e. their strong generative capacity.
in considering this aspect of a formalism, we hope to better understand the relationship between the structural descriptions generated by the grammars of a formalism, and the properties of semilinearity and polynomial recognizability.
we outlined the definition of a family of constrained grammatical formalisms, called linear context-free rewriting systems.
although embedding this version of lcfrs's in the framework of ilfp developed by rounds (1985) is straightforward, our motivation was to capture properties shared by a family of grammatical systems and generalize them defining a class of related formalisms.
for example, gazdar (1985) discusses the applicability of indexed grammars (ig's) to natural language in terms of the structural descriptions assigned; and berwick (1984) discusses the strong generative capacity of lexical-functional grammar (lfg) and government and bindings grammars (gb).
in considering the relationship between formalisms, we show that it is useful to abstract away from the details of the formalism, and examine the nature of their derivation process as reflected by properties their trees. find that several of the formalisms considered can be seen as being closely related since they have derivation tree sets with the same structure as those produced by context-free grammars on the basis of this observation, we describe a class of formalisms which we call linear context- free rewriting systems, and show they are recognizable in polynomial time and generate only semilinear languages.
in the next section, we show how an atm can accept the strings generated by a grammar in a lcfrs formalism in logspace, and hence show that each family can be recognized in polynomial time.
