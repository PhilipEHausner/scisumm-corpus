since 1995, a few statistical parsing algorithms have demonstrated a breakthrough in parsing accuracy, as measured against the upenn treebank as a gold standard.
we have demonstrated, at least for one problem, that a lexicalized, probabilistic context-free parser with head rules (lpcfghr) can be used effectively for information extraction.
in this paper, we report adapting a lexicalized, probabilistic context-free parser with head rules (lpcfg-hr) to information extraction.
we were already using a generative statistical model for part-of-speech tagging (weischedel et al. 1993), and more recently, had begun using a generative statistical model for name finding (bikel et al.
finally, our newly constructed parser, like that of (collins 1997), was based on a generative statistical model.
thus, each component of what would be the first three stages of our pipeline was based on the same general class of statistical model.
at each step in the process, a choice is made from a statistical distribution, with the probability of each possible selection dependent on particular features of previously generated elements.
instead, we applied an information retrieval system to select a large number of articles from the desired sources, yielding a corpus rich in the desired types of events.
in this section, we describe the algorithm that was used to automatically produce augmented trees, starting with a) human-generated semantic annotations and b) machinegenerated syntactic parse trees.
instead, our parsing algorithm, trained on the upenn treebank, was run on the new york times source to create unsupervised syntactic training which was constrained to be consistent with semantic annotation.
figure 4 shows an example of the semantic annotation, which was the only type of manual annotation we performed.
