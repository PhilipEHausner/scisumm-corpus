the precision and recall measures described in more detail in section used in evaluating treebank parsing treat each constituent as a separate entity a minimal unit of correctness 
furthermore we know one of the original parses will be the hypothesized parse so the direct method of determining which one is best is to compute the probability of each of the candidate parses using the probabilistic model we developed in section 
the bayes models were able to achieve significantly higher precision than their non parametric counterparts 
adding the isolated constituents to our hypothesis parse could increase our expected recall but in the cases we investigated it would invariably hurt our precision more than we would gain on recall 
the three parsers were trained and tuned by their creators on various sections of the wsj portion of the penn treebank leaving only sections and completely untouched during the development of any of the parsers 
their theoretical finding is simply stated classification error rate decreases toward the noise rate exponentially in the number of independent accurate classifiers 
the corpus based statistical parsing community has many fast and accurate automated parsing systems including systems produced by collins charniak and ratnaparkhi 
the maximum precision oracle is an upper bound on the possible gain we can achieve by parse hybridization 
in each figure the upper graph shows the isolated constituent precision and the bottom graph shows the corresponding number of hypothesized constituents 
the constituent voting and na ve bayes techniques are equivalent because the parameters learned in the training set did not sufficiently discriminate between the three parsers 
