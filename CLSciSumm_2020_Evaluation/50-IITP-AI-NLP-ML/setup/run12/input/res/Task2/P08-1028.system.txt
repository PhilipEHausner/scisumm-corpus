nlp tasks that could benefit from composition models include paraphrase identification and context dependent language modeling coccaro and jurafsky 
in addition bullinaria and levy found that these parameters perform well on a number of other tasks such as the synonymy task from the test ofenglish as a foreign language toefl 
the neighbors kintsch argues can strengthen features of the predicate that are appropriate for the argument of the predication animal stable village gallop jokey horse run unfortunately comparisons across vector composition models have been few and far between in the literature 
we employed leave one out resampling weiss and kulikowski by correlating the data obtained from each participant with the ratings obtained from all other participants 
for example simplistic approaches to handling sentences such as john loves mary and mary loves john typically fail to make valid representations in one of two ways 
computational models of semantics which use symbolic logic representations montague can account naturally for the meaning of phrases or sentences 
the lowest correlation p is observed for the simple additive model which is not significantly different from the non compositional baseline model 
the resulting vector is sparser but expresses more succinctly the meaning of the predicate argument structure and thus allows semantic similarity to be modelled more accurately 
analysis of similarity ratings the reliability of the collected judgments is important for our evaluation experiments we therefore performed several tests to validate the quality of the ratings 
to give a concrete example circular convolution is an instance of the general multiplicative model which breaks this constraint by allowing uj to contribute to pi for example according to the addition of the two vectors representing horse and run in figure would yield horse run 
