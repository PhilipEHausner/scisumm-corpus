since 1995, a few statistical parsing algorithms have demonstrated a breakthrough in parsing accuracy, as measured against the upenn treebank as a gold standard.
thus, each component of what would be the first three stages of our pipeline was based on the same general class of statistical model.
figure 4 shows an example of the semantic annotation, which was the only type of manual annotation we performed.
we have demonstrated, at least for one problem, that a lexicalized, probabilistic context-free parser with head rules (lpcfghr) can be used effectively for information extraction.
for example, an error made during part-of-speech-tagging may cause a future error in syntactic analysis, which may in turn cause a semantic interpretation failure.
chiba, (1999) was able to use such a parsing algorithm to reduce perplexity with the long term goal of improved speech recognition.
whenever two or more constituents are equivalent relative to all possible later parsing decisions, we apply dynamic programming, keeping only the most likely constituent in the chart.
in these trees, the standard treebank structures are augmented to convey semantic information, that is, entities and relations.
in this paper, we report adapting a lexicalized, probabilistic context-free parser with head rules (lpcfg-hr) to information extraction.
for the following example, the template relation in figure 2 was to be generated: &quot;donald m. goldstein, a historian at the university of pittsburgh who helped write...&quot;
we were already using a generative statistical model for part-of-speech tagging (weischedel et al. 1993), and more recently, had begun using a generative statistical model for name finding (bikel et al.
at each step in the process, a choice is made from a statistical distribution, with the probability of each possible selection dependent on particular features of previously generated elements.
