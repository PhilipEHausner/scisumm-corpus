think of dcs as a higher-level our system learns lexical associations between programming language tailored to natural language, words and predicates.
it is this transparency between syntax and semantics provided by dcs which leads to a simple and streamlined compositional semantics suitable for program induction.
the main technical contribution of this work is a new semantic representation, dependency-based compositional semantics (dcs), which is both simple and expressive (section 2).
for example, area (by virtue which results in programs (dcs trees) which are of being a noun) triggers many predicates: city, much simpler than the logically-equivalent lambda state, area, etc.
these rules are often too stringent, cused on aligning text to a world (liang et al., 2009), and for complex utterances, especially in free word- using text in reinforcement learning (branavan et al., order languages, either disharmonic combinators are 2009; branavan et al., 2010), and many others.
this yields a more system is based on a new semantic representation, factorized and flexible representation that is easier dcs, which offers a simple and expressive alterto search through and parametrize using features. native to lambda calculus.
aggregate relation dcs trees that only use join relations can represent arbitrarily complex compositional structures, but they cannot capture higherorder phenomena in language.
we first present a basic version (section 2.1) of dependency-based compositional semantics (dcs), which captures the core idea of using trees to represent formal semantics.
feedback from the context; for example, the lexical entry for borders world has been used to guide both syntactic parsing is s\np/np : ay.ax.border(x, y), which means (schuler, 2003) and semantic parsing (popescu et borders looks right for the first argument and left al., 2003; clarke et al., 2010).
