to keep the human annotator from missing errors made by the tagger, we additionally calculate the strongest competitor for each label g. if its probability is close to the winner (closeness is defined by a threshold on the quotient), the assignment is regarded as unreliable, and the annotator is asked to confirm the assignment.
during the first phase, the focus is on annotating correct structures and a coarse-grained classification of grammatical functions, which represent the following areas of information: dependency type: complements are further classified according to features such as category and case: clausal complements (oc), accusative objects (oa), datives (da), etc.
a problem for the rudimentary argument. structure representations is the use of incomplete structures in natural language, i.e. phenomena such as coordination and ellipsis.
since a precise structural description of non-constituent coordination would require a. rich inventory of incomplete phrase types, we have agreed on a sort of unde.rspe.cified representations: the coordinated units are assigned structures in which missing lexical material is not represented at the level of primary links.
in general, the resulting interpreted data also are closer to semantic annotation and more neutral with respect to particular syntactic theories.
apart from this rather technical problem, two further arguments speak against phrase structure as the structural pivot of the annotation scheme: finally, the structural handling of free word order means stating well-formedness constraints on structures involving many trace-filler dependencies, which has proved tedious.
accuracy of the unreliable 10% of assignments is 75%, i.e., the annotator has to alter the choice in 1 of 4 cases when asked for confirmation.
