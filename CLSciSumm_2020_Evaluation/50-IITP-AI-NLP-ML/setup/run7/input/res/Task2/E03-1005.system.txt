while sl-dop and ls-dop have been compared before in bod (2002), especially in the context of musical parsing, this paper presents the the dop approach is based on two distinctive features: (1) the use of corpus fragments rather than grammar rules, and (2) the use of arbitrarily large fragments rather than restricted ones.
together with a pcfgreduction of dop we obtain improved accuracy and efficiency on the wall street journal treebank our results show an 11% relative reduction in error rate over previous models, and an average processing time of 3.6 seconds per wsj sentence.
in bod (2000b), an alternative notion for the best parse tree was proposed based on a simplicity criterion: instead of producing the most probable tree, this model produced the tree generated by the shortest derivation with the fewest training subtrees.
for example, bod (2001) samples a fixed number of subtrees of each depth, which has the effect of assigning roughly equal weight to each node in the training data, and roughly exponentially less probability for larger trees (see goodman 2002: 12).
this may be explained by the fact our best results in bod (2001) were obtained by testing various subtree restrictions until the highest accuracy was obtained, while in the current experiment we used all subtrees as given by the pcfg-reduction.
in this paper, we will test a simple extension of goodman's compact pcfg-reduction of dop which has the same property as the normalization proposed in bod (2001) in that it assigns roughly equal weight to each node in the training data.
