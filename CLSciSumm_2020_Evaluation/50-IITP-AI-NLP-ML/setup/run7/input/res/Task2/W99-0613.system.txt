when this feature type was included, coboost chose this default feature at an early iteration, thereby giving non-abstaining pseudo-labels for all examples, with eventual convergence to the two classifiers agreeing by assigning the same label to almost all examples.
the following features were used: full-string=x the full string (e.g., for maury cooper, full- s tring=maury_cooper). contains(x) if the spelling contains more than one word, this feature applies for any words that the string contains (e.g., maury cooper contributes two such features, contains (maury) and contains (cooper) . allcapl this feature appears if the spelling is a single word which is all capitals (e.g., ibm would contribute this feature). allcap2 this feature appears if the spelling is a single word which is all capitals or full periods, and contains at least one period.
recent results (e.g., (yarowsky 95; brill 95; blum and mitchell 98)) have suggested that unlabeled data can be used quite profitably in reducing the need for supervision.
in the cotraining case, (blum and mitchell 98) argue that the task should be to induce functions ii and f2 such that so ii and 12 must (1) correctly classify the labeled examples, and (2) must agree with each other on the unlabeled examples.
a spelling rule might be a simple look-up for the string (e.g., a rule that honduras is a location) or a rule that looks at words within a string (e.g., a rule that any string containing mr. is a person).
the first method builds on results from (yarowsky 95) and (blum and mitchell 98).
