the second stage takes the output from the first and labels all the edges in the dependency graph with appropriate syntactic categories using a globally trained sequence classifier over components of the graph.
these weaknesses are not surprising, since these decisions encode the more global aspects of sentence structure: arrangement of clauses and adverbial dependents in multi-clause sentences, and prepositional phrase attachment.
we have presented results showing that the spanning tree dependency parsing framework of mcdonald et al. (mcdonald et al., 2005b; mcdonald and pereira, 2006) generalizes well to languages other than english.
in fact, for every language our models perform significantly higher than the average performance for all the systems reported in buchholz et al. (2006).
that work extends the maximum spanning tree dependency parsing framework (mcdonald et al., 2005a; mcdonald et al., 2005b) to incorporate features over multiple edges in the dependency graph.
furthermore, for arabic and spanish, we used lemmas instead of inflected word forms, again based on performance on held-out data1.
the first stage based on the unlabeled dependency parsing models described by mcdonald and pereira (2006) augmented with morphological features for a subset of the languages.
these results show that the discriminative spanning tree parsing framework (mcdonald et al., 2005b; mcdonald and pereira, 2006) is easily adapted across all these languages.
for instance, the system of mcdonald et al. (2005a) incorporates features over the part of speech of words occurring between and around a possible head-dependent relation.
we use the mira online learner to set the weights (crammer and singer, 2003; mcdonald et al., 2005a) since we found it trained quickly and provide good performance.
