n/p: allow non-projective/force projective, s/a: sequential labeling/atomic labeling, m/b: include morphology features/no morphology features. assignment of edge labels instead of individual assignment, and a rich feature set that incorporates morphological properties when available.
we use the mira online learner to set the weights (crammer and singer, 2003; mcdonald et al., 2005a) since we found it trained quickly and provide good performance.
we proceedings of the 10th conference on computational natural language learning (conll-x), pages 216–220, new york city, june 2006. c�2006 association for computational linguistics assume that all dependency graphs are trees but may be non-projective, both of which are true in the data sets we use.
for instance, the system of mcdonald et al. (2005a) incorporates features over the part of speech of words occurring between and around a possible head-dependent relation.
these results show that the discriminative spanning tree parsing framework (mcdonald et al., 2005b; mcdonald and pereira, 2006) is easily adapted across all these languages.
an exact projective and an approximate non-projective parsing algorithm are presented, since it is shown that nonprojective dependency parsing becomes np-hard when features are extended beyond a single edge.
other high-frequency word classes with relatively low attachment accuracy are prepositions (80%), adverbs (82%) and subordinating conjunctions (80%), for a total of another 23% of the test corpus.
the second stage takes the output from the first and labels all the edges in the dependency graph with appropriate syntactic categories using a globally trained sequence classifier over components of the graph.
we have presented results showing that the spanning tree dependency parsing framework of mcdonald et al. (mcdonald et al., 2005b; mcdonald and pereira, 2006) generalizes well to languages other than english.
