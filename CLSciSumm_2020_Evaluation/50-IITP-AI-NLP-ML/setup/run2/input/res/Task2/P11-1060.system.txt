rather than using lexical triggers, several of the other systems use ibm word alignment models to produce an initial word-predicate mapping.
to further reduce the search space, f imposes a few additional constraints, e.g., limiting the number of marked nodes to 2 and only allowing trace predicates between arity 1 predicates.
it is impossible to represent the semantics of this phrase with just a csp, so we introduce a new aggregate relation, notated e. consider a tree he:ci, whose root is connected to a child c via e. if the denotation of c is a set of values s, the parentâ€™s denotation is then a singleton set containing s. formally: figure 3(a) shows the dcs tree for our running example.
feedback from the context; for example, the lexical entry for borders world has been used to guide both syntactic parsing is s\np/np : ay.ax.border(x, y), which means (schuler, 2003) and semantic parsing (popescu et borders looks right for the first argument and left al., 2003; clarke et al., 2010).
as in clarke et al. (2010), we obviate the need for annotated logical forms by considering the endto-end problem of mapping questions to answers.
we find that only for a small fraction of training examples do the k-best sets contain any trees yielding the correct answer (29% for dcs on geo).
this algorithm is linear in the number of nodes times the size of the denotations.1 now the dual importance of trees in dcs is clear: we have seen that trees parallel syntactic dependency structure, which will facilitate parsing.
