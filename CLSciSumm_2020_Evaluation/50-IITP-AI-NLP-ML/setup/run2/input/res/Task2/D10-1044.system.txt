we obtained positive results using a very simple phrase-based system in two different adaptation settings: using english/french europarl to improve a performance on a small, specialized medical domain; and using non-news portions of the nist09 training material to improve performance on the news-related corpora.
this is a standard adaptation problem for smt.
the paper is structured as follows.
the linear lm (lin lm), tm (lin tm) and map tm (map tm) used with non-adapted counterparts perform in all cases slightly worse than the log-linear combination, which adapts both lm and tm components.
it is also worth pointing out a connection with daum´e’s (2007) work that splits each feature into domain-specific and general copies.
we model po(s|t) using a map criterion over weighted phrase-pair counts: and from the similarity to (5), assuming y = 0, we see that wλ(s, t) can be interpreted as approximating pf(s, t)/po(s, t).
moving beyond directly related work, major themes in smt adaptation include the ir (hildebrand et al., 2005; l¨u et al., 2007; zhao et al., 2004) and mixture (finch and sumita, 2008; foster and kuhn, 2007; koehn and schroeder, 2007; l¨u et al., 2007) approaches for lms and tms described above, as well as methods for exploiting monolingual in-domain text, typically by translating it automatically and then performing self training (bertoldi and federico, 2009; ueffing et al., 2007; schwenk and senellart, 2009).
experiments are presented in section 4.
however, for multinomial models like our lms and tms, there is a one to one correspondence between instances and features, eg the correspondence between a phrase pair (s, t) and its conditional multinomial probability p(s1t).
