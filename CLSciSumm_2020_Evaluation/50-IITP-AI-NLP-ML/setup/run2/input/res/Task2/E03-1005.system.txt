thus the major innovations of dop are: 2. the use of arbitrarily large fragments rather than restricted ones both have gained or are gaining wide usage, and are also becoming relevant for theoretical linguistics (see bod et al. 2003a).
although bod's method obtains very competitive results on the wall street journal (wsj) task, the parsing time was reported to be over 200 seconds per sentence (bod 2003).
johnson (1998b, 2002) showed that dop1's subtree estimation method is statistically biased and inconsistent.
the derivation with the smallest sum, or highest rank, is taken as the final best derivation producing the best parse tree in simplicity-dop.3 although bod (2000b) reports that simplicity dop is outperformed by likelihood-dop, its results are still rather impressive for such a simple model.
goodman then shows by simple induction that subderivations headed by a with external nonterminals at the roots and leaves, internal nonterminals elsewhere have probability 1/a.
in bod (2000b), an alternative notion for the best parse tree was proposed based on a simplicity criterion: instead of producing the most probable tree, this model produced the tree generated by the shortest derivation with the fewest training subtrees.
compared to bod (2001), our results show an 11% improvement in terms of relative error reduction and a speedup which reduces the processing time from 220 to 3.6 seconds per wsj sentence.
in this paper, we will test a simple extension of goodman's compact pcfg-reduction of dop which has the same property as the normalization proposed in bod (2001) in that it assigns roughly equal weight to each node in the training data.
