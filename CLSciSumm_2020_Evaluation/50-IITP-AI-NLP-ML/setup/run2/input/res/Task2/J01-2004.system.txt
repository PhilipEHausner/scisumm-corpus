this contrasts with our perplexity results reported above, as well as with the recognition experiments in chelba (2000), where the best results resulted from interpolated models.
he was able to reduce both sentence and word error rates on the atis corpus using this method.
in the event that no complete parse is found, the highest initially ranked parse on the last nonempty priority queue is returned.
their modifications included: (i) removing orthographic cues to structure (e.g., punctuation); (ii) replacing all numbers with the single token n; and (iii) closing the vocabulary at 10,000, replacing all other words with the unk token.
also, the parser returns a set of candidate parses, from which we have been choosing the top ranked; if we use an oracle to choose the parse with the highest accuracy from among the candidates (which averaged 70.0 in number per sentence), we find an average labeled precision/recall of 94.1, for sentences of length < 100.
these results, achieved using very straightforward conditioning events and considering only the left context, are within one to four points of the best published observed running time on section 23 of the penn treebank, with the full conditional probability model and beam of 10-11, using one 300 mhz ultrasparc processor and 256mb of ram of a sun enterprise 450. accuracies cited above.'
evaluation is carried out on a hand-parsed test corpus, and the manual parses are treated as correct.
if the left-hand side of the production is a pos, then the algorithm takes the right branch of the decision tree, and returns (at level 4) the pos of the closest c-commanding lexical head to a, which it finds by walking the parse tree; if the left-hand side of the rule is not a pos, then the algorithm returns (at level 4) the closest sibling to the left of the parent of constituent (a).
