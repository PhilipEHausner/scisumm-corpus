through parser combination we have reduced the precision error rate by 30% and the recall error rate by 6% compared to the best previously published result.
in equations 1 through 3 we develop the model for constructing our parse using naïve bayes classification.
furthermore, we know one of the original parses will be the hypothesized parse, so the direct method of determining which one is best is to compute the probability of each of the candidate parses using the probabilistic model we developed in section 2.1.
the bayes models were able to achieve significantly higher precision than their non-parametric counterparts.
it is the performance we could achieve if an omniscient observer told us which parser to pick for each of the sentences.
these three parsers have given the best reported parsing results on the penn treebank wall street journal corpus (marcus et al., 1993).
the combining algorithm is presented with the candidate parses and asked to choose which one is best.
similarly figures 1 and 2 show how the isolated constituent precision varies by sentence length and the size of the span of the hypothesized constituent.
the probabilistic version of this procedure is straightforward: we once again assume independence among our various member parsers.
the corpus-based statistical parsing community has many fast and accurate automated parsing systems, including systems produced by collins (1997), charniak (1997) and ratnaparkhi (1997).
the development of a naïve bayes classifier involves learning how much each parser should be trusted for the decisions it makes.
the precision and recall measures (described in more detail in section 3) used in evaluating treebank parsing treat each constituent as a separate entity, a minimal unit of correctness.
