Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,A00-2030,W01-0510,0,"Miller et al., 2000",0,"Section 5 compares our approach tooth ers in the literature, in particular that of (Miller et al., 2000)","Section 5 compares our approach too thiers in the literature, in particular that of (Miller et al., 2000)","['6', '22', '5', '21', '2']","['    <S sid=""6"" ssid=""4"">In this paper, we report adapting a lexicalized, probabilistic context-free parser with head rules (LPCFG-HR) to information extraction.</S>\n', '    <S sid=""22"" ssid=""5"">There is no opportunity for a later stage, such as parsing, to influence or correct an earlier stage such as part-of-speech tagging.</S>\n', '    <S sid=""5"" ssid=""3"">Chiba, (1999) was able to use such a parsing algorithm to reduce perplexity with the long term goal of improved speech recognition.</S>\n', '    <S sid=""21"" ssid=""4"">For example, an error made during part-of-speech-tagging may cause a future error in syntactic analysis, which may in turn cause a semantic interpretation failure.</S>\n', '    <S sid=""2"" ssid=""2"">In this paper we report adapting a lexic al ized, probabilistic context-free parser to information extraction and evaluate this new technique on MUC-7 template elements and template relations.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
2,A00-2030,W01-0510,0,"Miller et al, 2000",0,"The basic approach we described is very similar to the one presented in (Miller et al, 2000) however there are a few major di erences:  in our approach the augmentation of the syn tactic tags with semantic tags is straightforward due to the fact that the semantic constituents are matched exactly 5. The approach in (Miller","The basic approach we described is very similar to the one presented in (Miller et al, 2000) however there are a few major differences:  in our approach the augmentation of the syn tactic tags with semantic tags is straightforward due to the fact that the semantic constituents are matched exactly 5. The approach in (Miller","['84', '100', '74', '29', '21']","['    <S sid=""84"" ssid=""3"">Although mathematically the model predicts tree elements in a top-down fashion, we search the space bottom-up using a chartbased search.</S>\n', '    <S sid=""100"" ssid=""5"">Given multiple constituents that cover identical spans in the chart, only those constituents with probabilities within a While our focus throughout the project was on TE and TR, we became curious about how well the model did at part-of-speech tagging, syntactic parsing, and at name finding.</S>\n', '    <S sid=""74"" ssid=""15"">The categories for head constituents, cl&#8222; are predicted based solely on the category of the parent node, cp: Modifier constituent categories, cm, are predicted based on their parent node, cp, the head constituent of their parent node, chp, the previously generated modifier, c&#8222;,_1, and the head word of their parent, wp.</S>\n', '    <S sid=""29"" ssid=""12"">Thus, each component of what would be the first three stages of our pipeline was based on the same general class of statistical model.</S>\n', '    <S sid=""21"" ssid=""4"">For example, an error made during part-of-speech-tagging may cause a future error in syntactic analysis, which may in turn cause a semantic interpretation failure.</S>\n']","['Hypothesis_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
3,A00-2030,W01-0510,0,"Miller et al, 2000",0,"The semantic annotation required by our task is much simpler than that employed by (Miller et al, 2000)","The semantic annotation required by our task is much simpler than that employed by (Miller et al, 2000)","['43', '86', '32', '17', '82']","['    <S sid=""43"" ssid=""3"">Thus, we did not consider simply adding semantic labels to the existing Penn TREEBANK, which is drawn from a single source &#8212; the Wall Street Journal &#8212; and is impoverished in articles about rocket launches.</S>\n', '    <S sid=""86"" ssid=""5"">Whenever two or more constituents are equivalent relative to all possible later parsing decisions, we apply dynamic programming, keeping only the most likely constituent in the chart.</S>\n', '    <S sid=""32"" ssid=""15"">Because generative statistical models had already proven successful for each of the first three stages, we were optimistic that some of their properties &#8212; especially their ability to learn from large amounts of data, and their robustness when presented with unexpected inputs &#8212; would also benefit semantic analysis.</S>\n', '    <S sid=""17"" ssid=""7"">For the following example, the template relation in Figure 2 was to be generated: &amp;quot;Donald M. Goldstein, a historian at the University of Pittsburgh who helped write...&amp;quot;</S>\n', '    <S sid=""82"" ssid=""1"">Given a sentence to be analyzed, the search program must find the most likely semantic and syntactic interpretation.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
4,A00-2030,W01-0510,0,"Miller et al, 2000",0,"One possibly bene cial extension of our work suggested by (Miller et al, 2000) would be to add semantic tags describing relations between entities (slots), in which case the semantic constraints would not be structured strictly on the two levels used in the current approach, respectively frame and slot level","One possibly beneficial extension of our work suggested by (Miller et al, 2000) would be to add semantic tags describing relations between entities (slots), in which case the semantic constraints would not be structured strictly on the two levels used in the current approach, respectively frame and slot level","['32', '43', '29', '66', '28']","['    <S sid=""32"" ssid=""15"">Because generative statistical models had already proven successful for each of the first three stages, we were optimistic that some of their properties &#8212; especially their ability to learn from large amounts of data, and their robustness when presented with unexpected inputs &#8212; would also benefit semantic analysis.</S>\n', '    <S sid=""43"" ssid=""3"">Thus, we did not consider simply adding semantic labels to the existing Penn TREEBANK, which is drawn from a single source &#8212; the Wall Street Journal &#8212; and is impoverished in articles about rocket launches.</S>\n', '    <S sid=""29"" ssid=""12"">Thus, each component of what would be the first three stages of our pipeline was based on the same general class of statistical model.</S>\n', '    <S sid=""66"" ssid=""7"">At each step in the process, a choice is made from a statistical distribution, with the probability of each possible selection dependent on particular features of previously generated elements.</S>\n', '    <S sid=""28"" ssid=""11"">Finally, our newly constructed parser, like that of (Collins 1997), was based on a generative statistical model.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
5,A00-2030,W01-0510,0,"Miller et al, 2000",0,"Similar to the approach in (Miller et al, 2000 )weinitialized the SLM statistics from the UPenn Tree bank parse trees (about 1Mwds of training data) at the rst training stage, see Section 3","Similar to the approach in (Miller et al, 2000) we initialized the SLM statistics from the UPenn Tree bank parse trees","['66', '86', '12', '32', '29']","['    <S sid=""66"" ssid=""7"">At each step in the process, a choice is made from a statistical distribution, with the probability of each possible selection dependent on particular features of previously generated elements.</S>\n', '    <S sid=""86"" ssid=""5"">Whenever two or more constituents are equivalent relative to all possible later parsing decisions, we apply dynamic programming, keeping only the most likely constituent in the chart.</S>\n', '    <S sid=""12"" ssid=""2"">The Template Element (TE) task identifies organizations, persons, locations, and some artifacts (rocket and airplane-related artifacts).</S>\n', '    <S sid=""32"" ssid=""15"">Because generative statistical models had already proven successful for each of the first three stages, we were optimistic that some of their properties &#8212; especially their ability to learn from large amounts of data, and their robustness when presented with unexpected inputs &#8212; would also benefit semantic analysis.</S>\n', '    <S sid=""29"" ssid=""12"">Thus, each component of what would be the first three stages of our pipeline was based on the same general class of statistical model.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
6,A00-2030,P14-1078,0,"Miller et al, 2000",0,"Rule-based methods (Miller et al, 2000) employ a number of linguistic rules to capture relation patterns","Rule-based methods (Miller et al, 2000) employ a number of linguistic rules to capture relation patterns","['21', '32', '29', '104', '66']","['    <S sid=""21"" ssid=""4"">For example, an error made during part-of-speech-tagging may cause a future error in syntactic analysis, which may in turn cause a semantic interpretation failure.</S>\n', '    <S sid=""32"" ssid=""15"">Because generative statistical models had already proven successful for each of the first three stages, we were optimistic that some of their properties &#8212; especially their ability to learn from large amounts of data, and their robustness when presented with unexpected inputs &#8212; would also benefit semantic analysis.</S>\n', '    <S sid=""29"" ssid=""12"">Thus, each component of what would be the first three stages of our pipeline was based on the same general class of statistical model.</S>\n', '    <S sid=""104"" ssid=""1"">We have demonstrated, at least for one problem, that a lexicalized, probabilistic context-free parser with head rules (LPCFGHR) can be used effectively for information extraction.</S>\n', '    <S sid=""66"" ssid=""7"">At each step in the process, a choice is made from a statistical distribution, with the probability of each possible selection dependent on particular features of previously generated elements.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
7,A00-2030,P05-1061,0,2000,0,"One interesting system that does not belong to the above class is that of Miller et al (2000), who take the view that relation extraction is just a form of probabilistic parsing where parse trees are augmented to identify all relations","One interesting system that does not belong to the above class is that of Miller et al (2000), who take the view that relation extraction is just a form of probabilistic parsing where parse trees are augmented to identify all relations","['16', '32', '78', '55', '12']","['    <S sid=""16"" ssid=""6"">For the following example, the The Template Relations (TR) task involves identifying instances of three relations in the text: TR builds on TE in that TR reports binary relations between elements of TE.</S>\n', '    <S sid=""32"" ssid=""15"">Because generative statistical models had already proven successful for each of the first three stages, we were optimistic that some of their properties &#8212; especially their ability to learn from large amounts of data, and their robustness when presented with unexpected inputs &#8212; would also benefit semantic analysis.</S>\n', '    <S sid=""78"" ssid=""19"">If we generalize the tree components (constituent labels, words, tags, etc.) and treat them all as simply elements, e, and treat all the conditioning factors as the history, h, we can write:</S>\n', '    <S sid=""55"" ssid=""1"">syntactic modifier of the other, the inserted node serves to indicate the relation as well as the argument.</S>\n', '    <S sid=""12"" ssid=""2"">The Template Element (TE) task identifies organizations, persons, locations, and some artifacts (rocket and airplane-related artifacts).</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
8,A00-2030,P05-1053,0,2000,0,"Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees","Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees","['52', '55', '32', '34', '26']","['    <S sid=""52"" ssid=""1"">In this section, we describe the algorithm that was used to automatically produce augmented trees, starting with a) human-generated semantic annotations and b) machinegenerated syntactic parse trees.</S>\n', '    <S sid=""55"" ssid=""1"">syntactic modifier of the other, the inserted node serves to indicate the relation as well as the argument.</S>\n', '    <S sid=""32"" ssid=""15"">Because generative statistical models had already proven successful for each of the first three stages, we were optimistic that some of their properties &#8212; especially their ability to learn from large amounts of data, and their robustness when presented with unexpected inputs &#8212; would also benefit semantic analysis.</S>\n', '    <S sid=""34"" ssid=""2"">In these trees, the standard TREEBANK structures are augmented to convey semantic information, that is, entities and relations.</S>\n', '    <S sid=""26"" ssid=""9"">We were already using a generative statistical model for part-of-speech tagging (Weischedel et al. 1993), and more recently, had begun using a generative statistical model for name finding (Bikel et al.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
9,A00-2030,P05-1053,0,2000,0,"Complicated relation extraction tasks may also impose a big challenge to the modeling approach used by Miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model","Complicated relation extraction tasks may also impose a big challenge to the modeling approach used by Miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model","['82', '78', '86', '17', '104']","['    <S sid=""82"" ssid=""1"">Given a sentence to be analyzed, the search program must find the most likely semantic and syntactic interpretation.</S>\n', '    <S sid=""78"" ssid=""19"">If we generalize the tree components (constituent labels, words, tags, etc.) and treat them all as simply elements, e, and treat all the conditioning factors as the history, h, we can write:</S>\n', '    <S sid=""86"" ssid=""5"">Whenever two or more constituents are equivalent relative to all possible later parsing decisions, we apply dynamic programming, keeping only the most likely constituent in the chart.</S>\n', '    <S sid=""17"" ssid=""7"">For the following example, the template relation in Figure 2 was to be generated: &amp;quot;Donald M. Goldstein, a historian at the University of Pittsburgh who helped write...&amp;quot;</S>\n', '    <S sid=""104"" ssid=""1"">We have demonstrated, at least for one problem, that a lexicalized, probabilistic context-free parser with head rules (LPCFGHR) can be used effectively for information extraction.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
10,A00-2030,H05-1094,0,2000,0,"(Miller et al, 2000) have combined entity recognition, parsing, and relation extraction into a jointly-trained single statistical parsing model that achieves improved performance on all the subtasks. Part of the contribution of the current work is to suggest that joint decoding can be effective even when joint training is not possible because jointly-labeled data is unavailable","(Miller et al, 2000) have combined entity recognition, parsing, and relation extraction into a jointly-trained single statistical parsing model that achieves improved performance on all the subtasks. Part of the contribution of the current work is to suggest that joint decoding can be effective even when joint training is not possible because jointly-labeled data is unavailable","['13', '86', '19', '61', '100']","['    <S sid=""13"" ssid=""3"">For each organization in an article, one must identify all of its names as used in the article, its type (corporation, government, or other), and any significant description of it.</S>\n', '    <S sid=""86"" ssid=""5"">Whenever two or more constituents are equivalent relative to all possible later parsing decisions, we apply dynamic programming, keeping only the most likely constituent in the chart.</S>\n', '    <S sid=""19"" ssid=""2"">Currently, the prevailing architecture for dividing sentential processing is a four-stage pipeline consisting of: Since we were interested in exploiting recent advances in parsing, replacing the syntactic analysis stage of the standard pipeline with a modern statistical parser was an obvious possibility.</S>\n', '    <S sid=""61"" ssid=""2"">The detailed probability structure differs, however, in that it was designed to jointly perform part-of-speech tagging, name finding, syntactic parsing, and relation finding in a single process.</S>\n', '    <S sid=""100"" ssid=""5"">Given multiple constituents that cover identical spans in the chart, only those constituents with probabilities within a While our focus throughout the project was on TE and TR, we became curious about how well the model did at part-of-speech tagging, syntactic parsing, and at name finding.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
11,A00-2030,P04-1054,0,2000,0,Miller et al (2000) propose an integrated statistical parsing technique that augments parse trees with semantic labels denoting entity and relation types,Miller et al (2000) propose an integrated statistical parsing technique that augments parse trees with semantic labels denoting entity and relation types,"['78', '32', '16', '52', '66']","['    <S sid=""78"" ssid=""19"">If we generalize the tree components (constituent labels, words, tags, etc.) and treat them all as simply elements, e, and treat all the conditioning factors as the history, h, we can write:</S>\n', '    <S sid=""32"" ssid=""15"">Because generative statistical models had already proven successful for each of the first three stages, we were optimistic that some of their properties &#8212; especially their ability to learn from large amounts of data, and their robustness when presented with unexpected inputs &#8212; would also benefit semantic analysis.</S>\n', '    <S sid=""16"" ssid=""6"">For the following example, the The Template Relations (TR) task involves identifying instances of three relations in the text: TR builds on TE in that TR reports binary relations between elements of TE.</S>\n', '    <S sid=""52"" ssid=""1"">In this section, we describe the algorithm that was used to automatically produce augmented trees, starting with a) human-generated semantic annotations and b) machinegenerated syntactic parse trees.</S>\n', '    <S sid=""66"" ssid=""7"">At each step in the process, a choice is made from a statistical distribution, with the probability of each possible selection dependent on particular features of previously generated elements.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
12,A00-2030,P04-1054,0,2000,0,"WhereasMiller et al (2000) use a generative model to produce parse information as well as relation information, we hypothesize that a technique discriminatively trained to classify relations will achieve better performance","Whereas Miller et al (2000) use a generative model to produce parse information as well as relation information, we hypothesize that a technique discriminatively trained to classify relations will achieve better performance","['104', '55', '44', '2', '18']","['    <S sid=""104"" ssid=""1"">We have demonstrated, at least for one problem, that a lexicalized, probabilistic context-free parser with head rules (LPCFGHR) can be used effectively for information extraction.</S>\n', '    <S sid=""55"" ssid=""1"">syntactic modifier of the other, the inserted node serves to indicate the relation as well as the argument.</S>\n', '    <S sid=""44"" ssid=""4"">Instead, we applied an information retrieval system to select a large number of articles from the desired sources, yielding a corpus rich in the desired types of events.</S>\n', '    <S sid=""2"" ssid=""2"">In this paper we report adapting a lexic al ized, probabilistic context-free parser to information extraction and evaluate this new technique on MUC-7 template elements and template relations.</S>\n', '    <S sid=""18"" ssid=""1"">Almost all approaches to information extraction &#8212; even at the sentence level &#8212; are based on the divide-and-conquer strategy of reducing a complex problem to a set of simpler ones.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
13,A00-2030,W05-0602,0,"Miller et al, 2000",0,"The syntactic model in (Miller et al, 2000) is similar to Collins?, but doesnot use features like sub cat frames and distance measures","The syntactic model in (Miller et al, 2000) is similar to Collins', but does not use features like subcat frames and distance measures","['32', '28', '43', '96', '29']","['    <S sid=""32"" ssid=""15"">Because generative statistical models had already proven successful for each of the first three stages, we were optimistic that some of their properties &#8212; especially their ability to learn from large amounts of data, and their robustness when presented with unexpected inputs &#8212; would also benefit semantic analysis.</S>\n', '    <S sid=""28"" ssid=""11"">Finally, our newly constructed parser, like that of (Collins 1997), was based on a generative statistical model.</S>\n', '    <S sid=""43"" ssid=""3"">Thus, we did not consider simply adding semantic labels to the existing Penn TREEBANK, which is drawn from a single source &#8212; the Wall Street Journal &#8212; and is impoverished in articles about rocket launches.</S>\n', '    <S sid=""96"" ssid=""1"">Our system for MUC-7 consisted of the sentential model described in this paper, coupled with a simple probability model for cross-sentence merging.</S>\n', '    <S sid=""29"" ssid=""12"">Thus, each component of what would be the first three stages of our pipeline was based on the same general class of statistical model.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
14,A00-2030,N07-2041,0,"Miller et al, 2000",0,"Similar to the approach in (Miller et al, 2000) and (Kulick et al, 2004), our parser integrates both syntactic and semantic annotations into a single annotation as shown in Figure 2","Similar to the approach in (Miller et al, 2000) and (Kulick et al, 2004), our parser integrates both syntactic and semantic annotations into a single annotation as shown in Figure 2","['86', '10', '100', '1', '82']","['    <S sid=""86"" ssid=""5"">Whenever two or more constituents are equivalent relative to all possible later parsing decisions, we apply dynamic programming, keeping only the most likely constituent in the chart.</S>\n', '    <S sid=""10"" ssid=""8"">Instead, our parsing algorithm, trained on the UPenn TREEBANK, was run on the New York Times source to create unsupervised syntactic training which was constrained to be consistent with semantic annotation.</S>\n', '    <S sid=""100"" ssid=""5"">Given multiple constituents that cover identical spans in the chart, only those constituents with probabilities within a While our focus throughout the project was on TE and TR, we became curious about how well the model did at part-of-speech tagging, syntactic parsing, and at name finding.</S>\n', '    <S sid=""1"" ssid=""1"">Since 1995, a few statistical parsing algorithms have demonstrated a breakthrough in parsing accuracy, as measured against the UPenn TREEBANK as a gold standard.</S>\n', '    <S sid=""82"" ssid=""1"">Given a sentence to be analyzed, the search program must find the most likely semantic and syntactic interpretation.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
15,A00-2030,W10-2924,0,2000,0,Miller et al (2000) adapt a probabilistic context-free parser for information extraction by augmenting syntactic labels with entity and relation labels,Miller et al (2000) adapt a probabilistic context-free parser for information extraction by augmenting syntactic labels with entity and relation labels,"['16', '91', '13', '78', '2']","['    <S sid=""16"" ssid=""6"">For the following example, the The Template Relations (TR) task involves identifying instances of three relations in the text: TR builds on TE in that TR reports binary relations between elements of TE.</S>\n', '    <S sid=""91"" ssid=""10"">The probability of generating a constituent of the specified category, starting at the topmost node.</S>\n', '    <S sid=""13"" ssid=""3"">For each organization in an article, one must identify all of its names as used in the article, its type (corporation, government, or other), and any significant description of it.</S>\n', '    <S sid=""78"" ssid=""19"">If we generalize the tree components (constituent labels, words, tags, etc.) and treat them all as simply elements, e, and treat all the conditioning factors as the history, h, we can write:</S>\n', '    <S sid=""2"" ssid=""2"">In this paper we report adapting a lexic al ized, probabilistic context-free parser to information extraction and evaluate this new technique on MUC-7 template elements and template relations.</S>\n']","['Result_Citation', 'Hypothesis_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
16,A00-2030,W06-0508,0,"Miller et al, 2000",0,"Most of the approaches for relation extraction rely on the mapping of syntactic dependencies, such as SVO, onto semantic relations, using either pattern matching or other strategies, such as probabilistic parsing for trees augmented with annotations for entities and relations (Miller et al 2000), or clustering of semantically similar syntactic dependencies, according to their selectional restrictions (Gamallo et al, 2002)","Most of the approaches for relation extraction rely on the mapping of syntactic dependencies, such as SVO, onto semantic relations, using either pattern matching or other strategies, such as probabilistic parsing for trees augmented with annotations for entities and relations (Miller et al 2000), or clustering of semantically similar syntactic dependencies, according to their selectional restrictions (Gamallo et al, 2002)","['19', '10', '86', '82', '13']","['    <S sid=""19"" ssid=""2"">Currently, the prevailing architecture for dividing sentential processing is a four-stage pipeline consisting of: Since we were interested in exploiting recent advances in parsing, replacing the syntactic analysis stage of the standard pipeline with a modern statistical parser was an obvious possibility.</S>\n', '    <S sid=""10"" ssid=""8"">Instead, our parsing algorithm, trained on the UPenn TREEBANK, was run on the New York Times source to create unsupervised syntactic training which was constrained to be consistent with semantic annotation.</S>\n', '    <S sid=""86"" ssid=""5"">Whenever two or more constituents are equivalent relative to all possible later parsing decisions, we apply dynamic programming, keeping only the most likely constituent in the chart.</S>\n', '    <S sid=""82"" ssid=""1"">Given a sentence to be analyzed, the search program must find the most likely semantic and syntactic interpretation.</S>\n', '    <S sid=""13"" ssid=""3"">For each organization in an article, one must identify all of its names as used in the article, its type (corporation, government, or other), and any significant description of it.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
17,A00-2030,P07-1055,0,"Miller et al, 2000",0,"This includes parsing and relation extraction (Miller et al, 2000), entity labeling and relation extraction (Roth and Yih, 2004), and part-of-speech tagging and chunking (Sutton et al, 2004)","This includes parsing and relation extraction (Miller et al, 2000), entity labeling and relation extraction (Roth and Yih, 2004), and part-of-speech tagging and chunking (Sutton et al, 2004)","['100', '86', '17', '91', '89']","['    <S sid=""100"" ssid=""5"">Given multiple constituents that cover identical spans in the chart, only those constituents with probabilities within a While our focus throughout the project was on TE and TR, we became curious about how well the model did at part-of-speech tagging, syntactic parsing, and at name finding.</S>\n', '    <S sid=""86"" ssid=""5"">Whenever two or more constituents are equivalent relative to all possible later parsing decisions, we apply dynamic programming, keeping only the most likely constituent in the chart.</S>\n', '    <S sid=""17"" ssid=""7"">For the following example, the template relation in Figure 2 was to be generated: &amp;quot;Donald M. Goldstein, a historian at the University of Pittsburgh who helped write...&amp;quot;</S>\n', '    <S sid=""91"" ssid=""10"">The probability of generating a constituent of the specified category, starting at the topmost node.</S>\n', '    <S sid=""89"" ssid=""8"">We can think of this prior probability as an estimate of the probability of generating a subtree with the constituent category, starting at the topmost node.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Hypothesis_Citation', 'Result_Citation']"
18,A00-2030,W05-0636,0,2000,0,"For example, Miller et al (2000) showed that performing parsing and information extraction in a joint model improves performance on both tasks","For example, Miller et al (2000) showed that performing parsing and information extraction in a joint model improves performance on both tasks","['50', '81', '79', '23', '18']","['    <S sid=""50"" ssid=""10"">Figure 4 shows an example of the semantic annotation, which was the only type of manual annotation we performed.</S>\n', '    <S sid=""81"" ssid=""3"">For modifier constituents, the mixture components are: For part-of-speech tags, the mixture components are: Finally, for word features, the mixture components are:</S>\n', '    <S sid=""79"" ssid=""1"">Maximum likelihood estimates for the model probabilities can be obtained by observing frequencies in the training corpus.</S>\n', '    <S sid=""23"" ssid=""6"">An integrated model can limit the propagation of errors by making all decisions jointly.</S>\n', '    <S sid=""18"" ssid=""1"">Almost all approaches to information extraction &#8212; even at the sentence level &#8212; are based on the divide-and-conquer strategy of reducing a complex problem to a set of simpler ones.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
19,A00-2030,N06-1037,0,2000,0,Miller et al (2000) address the task of relation extraction from the statistical parsing viewpoint,Miller et al (2000) address the task of relation extraction from the statistical parsing viewpoint,"['16', '12', '19', '10', '43']","['    <S sid=""16"" ssid=""6"">For the following example, the The Template Relations (TR) task involves identifying instances of three relations in the text: TR builds on TE in that TR reports binary relations between elements of TE.</S>\n', '    <S sid=""12"" ssid=""2"">The Template Element (TE) task identifies organizations, persons, locations, and some artifacts (rocket and airplane-related artifacts).</S>\n', '    <S sid=""19"" ssid=""2"">Currently, the prevailing architecture for dividing sentential processing is a four-stage pipeline consisting of: Since we were interested in exploiting recent advances in parsing, replacing the syntactic analysis stage of the standard pipeline with a modern statistical parser was an obvious possibility.</S>\n', '    <S sid=""10"" ssid=""8"">Instead, our parsing algorithm, trained on the UPenn TREEBANK, was run on the New York Times source to create unsupervised syntactic training which was constrained to be consistent with semantic annotation.</S>\n', '    <S sid=""43"" ssid=""3"">Thus, we did not consider simply adding semantic labels to the existing Penn TREEBANK, which is drawn from a single source &#8212; the Wall Street Journal &#8212; and is impoverished in articles about rocket launches.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
