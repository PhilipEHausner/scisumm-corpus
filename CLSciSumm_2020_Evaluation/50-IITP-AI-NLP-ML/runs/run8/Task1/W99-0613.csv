Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,W99-0613,N01-1023,0,"Collins and Singer, 1999",0,"Co-Training has been used before in applications like word-sense disambiguation (Yarowsky, 1995), web-page classification (Blum and Mitchell, 1998) and named entity identification (Collins and Singer, 1999)","Co-Training has been used before in applications like word-sense disambiguation (Yarowsky, 1995), web-page classification (Blum and Mitchell, 1998) and named entity identification (Collins and Singer, 1999)","['35', '251', '145', '43', '15']","['    <S sid=""35"" ssid=""29"">AdaBoost finds a weighted combination of simple (weak) classifiers, where the weights are chosen to minimize a function that bounds the classification error on a set of training examples.</S>\n', '    <S sid=""251"" ssid=""2"">In addition to a heuristic based on decision list learning, we also presented a boosting-like framework that builds on ideas from (Blum and Mitchell 98).</S>\n', '    <S sid=""145"" ssid=""12"">AdaBoost is given access to a weak learning algorithm, which accepts as input the training examples, along with a distribution over the instances.</S>\n', '    <S sid=""43"" ssid=""37"">The approach builds from an initial seed set for a category, and is quite similar to the decision list approach described in (Yarowsky 95).</S>\n', '    <S sid=""15"" ssid=""9"">The task can be considered to be one component of the MUC (MUC-6, 1995) named entity task (the other task is that of segmentation, i.e., pulling possible people, places and locations from text before sending them to the classifier).</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Hypothesis_Citation', 'Result_Citation']"
2,W99-0613,N01-1023,0,"Collins and Singer, 1999",0,"They also discuss an application of classifying web pages by using their method of mutually constrained models. (Collins and Singer, 1999) further extend the use of classifiers that have mutual constraints by adding terms toAdaBoost which force the classifiers to agree (called Co Boosting)","(Collins and Singer, 1999) further extend the use of classifiers that have mutual constraints by adding terms to AdaBoost which force the classifiers to agree (called Co Boosting)","['33', '203', '177', '61', '6']","['    <S sid=""33"" ssid=""27"">The second algorithm builds on a boosting algorithm called AdaBoost (Freund and Schapire 97; Schapire and Singer 98).</S>\n', '    <S sid=""203"" ssid=""70"">Several extensions of AdaBoost for multiclass problems have been suggested (Freund and Schapire 97; Schapire and Singer 98).</S>\n', '    <S sid=""177"" ssid=""44"">Formally, let el (62) be the number of classification errors of the first (second) learner on the training data, and let Eco be the number of unlabeled examples on which the two classifiers disagree.</S>\n', '    <S sid=""61"" ssid=""15"">The following features were used: full-string=x The full string (e.g., for Maury Cooper, full- s tring=Maury_Cooper). contains(x) If the spelling contains more than one word, this feature applies for any words that the string contains (e.g., Maury Cooper contributes two such features, contains (Maury) and contains (Cooper) . allcapl This feature appears if the spelling is a single word which is all capitals (e.g., IBM would contribute this feature). allcap2 This feature appears if the spelling is a single word which is all capitals or full periods, and contains at least one period.</S>\n', '    <S sid=""6"" ssid=""6"">The second algorithm extends ideas from boosting algorithms, designed for supervised learning tasks, to the framework suggested by (Blum and Mitchell 98).</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
3,W99-0613,W03-1509,0,Collins and Singer 1999,0,"Recent methods for English NER focus on machine-learning algorithms such as DL-CoTrain, CoBoost [Collins and Singer 1999], HMM [Daniel M. Bikel 1997], maximum entropy model [Borthwick, et al 1999] and so on","Recent methods for English NER focus on machine-learning algorithms such as DL-CoTrain, CoBoost [Collins and Singer 1999], HMM [Daniel M. Bikel 1997], maximum entropy model [Borthwick, et al 1999] and so on","['79', '204', '33', '108', '35']","['    <S sid=""79"" ssid=""12"">2 We now introduce a new algorithm for learning from unlabeled examples, which we will call DLCoTrain (DL stands for decision list, the term Cotrain is taken from (Blum and Mitchell 98)).</S>\n', '    <S sid=""204"" ssid=""71"">In this work we extended the AdaBoost.MH (Schapire and Singer 98) algorithm to the cotraining case.</S>\n', '    <S sid=""33"" ssid=""27"">The second algorithm builds on a boosting algorithm called AdaBoost (Freund and Schapire 97; Schapire and Singer 98).</S>\n', '    <S sid=""108"" ssid=""41"">In the cotraining case, (Blum and Mitchell 98) argue that the task should be to induce functions Ii and f2 such that So Ii and 12 must (1) correctly classify the labeled examples, and (2) must agree with each other on the unlabeled examples.</S>\n', '    <S sid=""35"" ssid=""29"">AdaBoost finds a weighted combination of simple (weak) classifiers, where the weights are chosen to minimize a function that bounds the classification error on a set of training examples.</S>\n']","['Result_Citation', 'Method_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
4,W99-0613,C02-1154,0,"Collins and Singer, 1999",0,"DL-CoTrain, (Collins and Singer, 1999), learns capitalized proper name NEs from a syn tactically analyzed corpus","DL-CoTrain, (Collins and Singer, 1999), learns capitalized proper name NEs from a syntactically analyzed corpus","['61', '43', '109', '237', '33']","['    <S sid=""61"" ssid=""15"">The following features were used: full-string=x The full string (e.g., for Maury Cooper, full- s tring=Maury_Cooper). contains(x) If the spelling contains more than one word, this feature applies for any words that the string contains (e.g., Maury Cooper contributes two such features, contains (Maury) and contains (Cooper) . allcapl This feature appears if the spelling is a single word which is all capitals (e.g., IBM would contribute this feature). allcap2 This feature appears if the spelling is a single word which is all capitals or full periods, and contains at least one period.</S>\n', '    <S sid=""43"" ssid=""37"">The approach builds from an initial seed set for a category, and is quite similar to the decision list approach described in (Yarowsky 95).</S>\n', '    <S sid=""109"" ssid=""42"">The key point is that the second constraint can be remarkably powerful in reducing the complexity of the learning problem.</S>\n', '    <S sid=""237"" ssid=""4"">The numbers falling into the location, person, organization categories were 186, 289 and 402 respectively.</S>\n', '    <S sid=""33"" ssid=""27"">The second algorithm builds on a boosting algorithm called AdaBoost (Freund and Schapire 97; Schapire and Singer 98).</S>\n']","['Result_Citation', 'Hypothesis_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
5,W99-0613,C02-1154,0,"Collins and Singer, 1999",0,"(Collins and Singer, 1999) also makes use of competing categories (person, organization, and location), which cover 96% of all the instances itset out to classify","(Collins and Singer, 1999) also makes use of competing categories (person, organization, and location), which cover 96% of all the instances it set out to classify","['237', '15', '10', '145', '236']","['    <S sid=""237"" ssid=""4"">The numbers falling into the location, person, organization categories were 186, 289 and 402 respectively.</S>\n', '    <S sid=""15"" ssid=""9"">The task can be considered to be one component of the MUC (MUC-6, 1995) named entity task (the other task is that of segmentation, i.e., pulling possible people, places and locations from text before sending them to the classifier).</S>\n', '    <S sid=""10"" ssid=""4"">The task is to learn a function from an input string (proper name) to its type, which we will assume to be one of the categories Person, Organization, or Location.</S>\n', '    <S sid=""145"" ssid=""12"">AdaBoost is given access to a weak learning algorithm, which accepts as input the training examples, along with a distribution over the instances.</S>\n', '    <S sid=""236"" ssid=""3"">We chose one of four labels for each example: location, person, organization, or noise where the noise category was used for items that were outside the three categories.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
6,W99-0613,W06-2204,0,"Collins and Singer, 1999",0,"In (Collins and Singer, 1999) Collins and Singer show that unlabeled data can be used to reduce the level of supervision required for named entity classification","In (Collins and Singer, 1999) Collins and Singer show that unlabeled data can be used to reduce the level of supervision required for named entity classification","['87', '8', '125', '219', '251']","['    <S sid=""87"" ssid=""20"">Otherwise, label the training data with the combined spelling/contextual decision list, then induce a final decision list from the labeled examples where all rules (regardless of strength) are added to the decision list.</S>\n', '    <S sid=""8"" ssid=""2"">Recent results (e.g., (Yarowsky 95; Brill 95; Blum and Mitchell 98)) have suggested that unlabeled data can be used quite profitably in reducing the need for supervision.</S>\n', '    <S sid=""125"" ssid=""58"">It may be more realistic to replace the second criteria with a softer one, for example (Blum and Mitchell 98) suggest the alternative Alternatively, if Ii and 12 are probabilistic learners, it might make sense to encode the second constraint as one of minimizing some measure of the distance between the distributions given by the two learners.</S>\n', '    <S sid=""219"" ssid=""86"">Finally, we would like to note that it is possible to devise similar algorithms based with other objective functions than the one given in Equ.</S>\n', '    <S sid=""251"" ssid=""2"">In addition to a heuristic based on decision list learning, we also presented a boosting-like framework that builds on ideas from (Blum and Mitchell 98).</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
8,W99-0613,W03-1022,0,"Collins and Singer, 1999",0,"Collins and Singer (1999) for example report that 88% of the named entities occurring in their data set belong to these three categories (Collins and Singer, 1999)","Collins and Singer (1999) for example report that 88% of the named entities occurring in their data set belong to these three categories (Collins and Singer, 1999)","['125', '47', '237', '217', '236']","['    <S sid=""125"" ssid=""58"">It may be more realistic to replace the second criteria with a softer one, for example (Blum and Mitchell 98) suggest the alternative Alternatively, if Ii and 12 are probabilistic learners, it might make sense to encode the second constraint as one of minimizing some measure of the distance between the distributions given by the two learners.</S>\n', '    <S sid=""47"" ssid=""1"">971,746 sentences of New York Times text were parsed using the parser of (Collins 96).1 Word sequences that met the following criteria were then extracted as named entity examples: whose head is a singular noun (tagged NN).</S>\n', '    <S sid=""237"" ssid=""4"">The numbers falling into the location, person, organization categories were 186, 289 and 402 respectively.</S>\n', '    <S sid=""217"" ssid=""84"">When this feature type was included, CoBoost chose this default feature at an early iteration, thereby giving non-abstaining pseudo-labels for all examples, with eventual convergence to the two classifiers agreeing by assigning the same label to almost all examples.</S>\n', '    <S sid=""236"" ssid=""3"">We chose one of four labels for each example: location, person, organization, or noise where the noise category was used for items that were outside the three categories.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
9,W99-0613,E09-1018,0,"Collinsand Singer, 1999",0,"While EM has worked quite well for a few tasks, notably ma chine translations (starting with the IBM models 1-5 (Brown et al, 1993), it has not had success inmost others, such as part-of-speech tagging (Merialdo, 1991), named-entity recognition (Collinsand Singer, 1999) and context-free-grammar induction (numerous attempts, too many to mention)","While EM has worked quite well for a few tasks, notably machine translations (starting with the IBM models 1-5 (Brown et al, 1993), it has not had success in most others, such as part-of-speech tagging (Merialdo, 1991), named-entity recognition (Collinsand Singer, 1999) and context-free-grammar induction (numerous attempts, too many to mention)","['47', '79', '89', '15', '125']","['    <S sid=""47"" ssid=""1"">971,746 sentences of New York Times text were parsed using the parser of (Collins 96).1 Word sequences that met the following criteria were then extracted as named entity examples: whose head is a singular noun (tagged NN).</S>\n', '    <S sid=""79"" ssid=""12"">2 We now introduce a new algorithm for learning from unlabeled examples, which we will call DLCoTrain (DL stands for decision list, the term Cotrain is taken from (Blum and Mitchell 98)).</S>\n', '    <S sid=""89"" ssid=""22"">The core of Yarowsky\'s algorithm is as follows: where h is defined by the formula in equation 2, with counts restricted to training data examples that have been labeled in step 2.</S>\n', '    <S sid=""15"" ssid=""9"">The task can be considered to be one component of the MUC (MUC-6, 1995) named entity task (the other task is that of segmentation, i.e., pulling possible people, places and locations from text before sending them to the classifier).</S>\n', '    <S sid=""125"" ssid=""58"">It may be more realistic to replace the second criteria with a softer one, for example (Blum and Mitchell 98) suggest the alternative Alternatively, if Ii and 12 are probabilistic learners, it might make sense to encode the second constraint as one of minimizing some measure of the distance between the distributions given by the two learners.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
11,W99-0613,W07-1712,0,"Collins and Singer, 1999",0,"In addition, we would also like to explore the semi-supervised techniques such as co-training and self-training (Collins and Singer, 1999)","In addition, we would also like to explore the semi-supervised techniques such as co-training and self-training (Collins and Singer, 1999)","['251', '219', '87', '145', '89']","['    <S sid=""251"" ssid=""2"">In addition to a heuristic based on decision list learning, we also presented a boosting-like framework that builds on ideas from (Blum and Mitchell 98).</S>\n', '    <S sid=""219"" ssid=""86"">Finally, we would like to note that it is possible to devise similar algorithms based with other objective functions than the one given in Equ.</S>\n', '    <S sid=""87"" ssid=""20"">Otherwise, label the training data with the combined spelling/contextual decision list, then induce a final decision list from the labeled examples where all rules (regardless of strength) are added to the decision list.</S>\n', '    <S sid=""145"" ssid=""12"">AdaBoost is given access to a weak learning algorithm, which accepts as input the training examples, along with a distribution over the instances.</S>\n', '    <S sid=""89"" ssid=""22"">The core of Yarowsky\'s algorithm is as follows: where h is defined by the formula in equation 2, with counts restricted to training data examples that have been labeled in step 2.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
12,W99-0613,W09-2208,0,"Collins and Singer, 1999",0,"Collins et al (Collins and Singer, 1999) proposed two algorithms for NER by modifying Yarowsky ?smethod (Yarowsky, 1995) and the framework suggested by (Blum and Mitchell, 1998)","Collins et al (Collins and Singer, 1999) proposed two algorithms for NER by modifying Yarowsky's method (Yarowsky, 1995) and the framework suggested by (Blum and Mitchell, 1998)","['27', '33', '89', '11', '80']","['    <S sid=""27"" ssid=""21"">The first method builds on results from (Yarowsky 95) and (Blum and Mitchell 98).</S>\n', '    <S sid=""33"" ssid=""27"">The second algorithm builds on a boosting algorithm called AdaBoost (Freund and Schapire 97; Schapire and Singer 98).</S>\n', '    <S sid=""89"" ssid=""22"">The core of Yarowsky\'s algorithm is as follows: where h is defined by the formula in equation 2, with counts restricted to training data examples that have been labeled in step 2.</S>\n', '    <S sid=""11"" ssid=""5"">For example, a good classifier would identify Mrs. Frank as a person, Steptoe &amp; Johnson as a company, and Honduras as a location.</S>\n', '    <S sid=""80"" ssid=""13"">The 2(Yarowsky 95) describes the use of more sophisticated smoothing methods.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Hypothesis_Citation', 'Hypothesis_Citation']"
13,W99-0613,W06-2207,0,"Collins and Singer, 1999",0,"This approach was shown to perform well on real-world natural language problems (Collins and Singer, 1999)","This approach was shown to perform well on real-world natural language problems (Collins and Singer, 1999)","['61', '13', '62', '33', '63']","['    <S sid=""61"" ssid=""15"">The following features were used: full-string=x The full string (e.g., for Maury Cooper, full- s tring=Maury_Cooper). contains(x) If the spelling contains more than one word, this feature applies for any words that the string contains (e.g., Maury Cooper contributes two such features, contains (Maury) and contains (Cooper) . allcapl This feature appears if the spelling is a single word which is all capitals (e.g., IBM would contribute this feature). allcap2 This feature appears if the spelling is a single word which is all capitals or full periods, and contains at least one period.</S>\n', '    <S sid=""13"" ssid=""7"">A spelling rule might be a simple look-up for the string (e.g., a rule that Honduras is a location) or a rule that looks at words within a string (e.g., a rule that any string containing Mr. is a person).</S>\n', '    <S sid=""62"" ssid=""16"">(e.g., N.Y. would contribute this feature, IBM would not). nonalpha=x Appears if the spelling contains any characters other than upper or lower case letters.</S>\n', '    <S sid=""33"" ssid=""27"">The second algorithm builds on a boosting algorithm called AdaBoost (Freund and Schapire 97; Schapire and Singer 98).</S>\n', '    <S sid=""63"" ssid=""17"">In this case nonalpha is the string formed by removing all upper/lower case letters from the spelling (e.g., for Thomas E. Petry nonalpha= .</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
15,W99-0613,W06-2207,0,"Collins and Singer, 1999",0,"(6) Similarly to (Collins and Singer, 1999) we used T= 0.95 for all experiments reported here","(6) Similarly to (Collins and Singer, 1999) we used T= 0.95 for all experiments reported here","['177', '69', '28', '203', '253']","['    <S sid=""177"" ssid=""44"">Formally, let el (62) be the number of classification errors of the first (second) learner on the training data, and let Eco be the number of unlabeled examples on which the two classifiers disagree.</S>\n', '    <S sid=""69"" ssid=""2"">Before describing the unsupervised case we first describe the supervised version of the algorithm: Input to the learning algorithm: n labeled examples of the form (xi, y&#8222;). y, is the label of the ith example (given that there are k possible labels, y, is a member of y = {1 ... 0). xi is a set of mi features {x,1, Xi2 .</S>\n', '    <S sid=""28"" ssid=""22"">(Yarowsky 95) describes an algorithm for word-sense disambiguation that exploits redundancy in contextual features, and gives impressive performance.</S>\n', '    <S sid=""203"" ssid=""70"">Several extensions of AdaBoost for multiclass problems have been suggested (Freund and Schapire 97; Schapire and Singer 98).</S>\n', '    <S sid=""253"" ssid=""4"">We are currently exploring other methods that employ similar ideas and their formal properties.</S>\n']","['Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
16,W99-0613,P12-1065,0,1999,0,We use Collins and Singer (1999) for our exact specification of Yarowsky.2 It uses DL rule scores ?fj?| ?fj |+ |? f |+ L (1) where  is a smoothing constant,We use Collins and Singer (1999) for our exact specification of Yarowsky,"['35', '43', '145', '15', '95']","['    <S sid=""35"" ssid=""29"">AdaBoost finds a weighted combination of simple (weak) classifiers, where the weights are chosen to minimize a function that bounds the classification error on a set of training examples.</S>\n', '    <S sid=""43"" ssid=""37"">The approach builds from an initial seed set for a category, and is quite similar to the decision list approach described in (Yarowsky 95).</S>\n', '    <S sid=""145"" ssid=""12"">AdaBoost is given access to a weak learning algorithm, which accepts as input the training examples, along with a distribution over the instances.</S>\n', '    <S sid=""15"" ssid=""9"">The task can be considered to be one component of the MUC (MUC-6, 1995) named entity task (the other task is that of segmentation, i.e., pulling possible people, places and locations from text before sending them to the classifier).</S>\n', '    <S sid=""95"" ssid=""28"">(Specifically, the limit n starts at 5 and increases by 5 at each iteration.)</S>\n']","['Result_Citation', 'Hypothesis_Citation', 'Result_Citation', 'Result_Citation', 'Result_Citation']"
