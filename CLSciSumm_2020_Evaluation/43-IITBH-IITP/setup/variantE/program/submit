Unlike Germann et al. (2009)  we chose a model size so that all benchmarks fit comfortably in main memory.
KenLM: Faster and Smaller Language Model Queries
RandLM and SRILM also remove context that will not extend  but SRILM performs a second lookup in its trie whereas our approach has minimal additional cost.
Our TRIE implements the popular reverse trie  in which the last word of an n-gram is looked up first  as do SRILM  IRSTLMâ€™s inverted variant  and BerkeleyLM except for the scrolling variant.
Our test machine has two Intel Xeon E5410 processors totaling eight cores  32 GB RAM  and four Seagate Barracuda disks in software RAID 0 running Linux 2.6.18.