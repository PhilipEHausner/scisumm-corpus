Citance Number,Citation Marker,Citation Marker Offset,Citation Offset,Citation Text,Citing Article,Discourse Facet,Reference Article,Reference Offset,Reference Text,Reference Text Clean,fileName
2,"McDonald et al, 2006",,0,"Introduce through post-processing ,e.g. through reattachment rules (Bick, 2006) or if the change increases overall parse tree probability (McDonald et al, 2006)",W06-2920,Results_Citation,W06-2932,'77',"<S sid=""77"" ssid=""15"">Similar improvements are common across all languages, though not as dramatic.</S>","<S sid=""77"" ssid=""15"">Similar improvements are common across all languages, though not as dramatic.</S>",W06-2932.csv
3,2006,0,0,Table 5 shows the official results for submitted parser outputs.31 The two participant groups with the highest total score are McDonald et al (2006) and Nivre et al (2006),W06-2920,Results_Citation,W06-2932,'61',"<S sid=""61"" ssid=""9"">In fact, for every language our models perform significantly higher than the average performance for all the systems reported in Buchholz et al. (2006).</S>","<S sid=""61"" ssid=""9"">In fact, for every language our models perform significantly higher than the average performance for all the systems reported in Buchholz et al. (2006).</S>",W06-2932.csv
4,2006,0,0,"Even though McDonald et al (2006) and Nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences",W06-2920,Hypothesis_Citation,W06-2932,'81',"<S sid=""81"" ssid=""3"">Other high-frequency word classes with relatively low attachment accuracy are prepositions (80%), adverbs (82%) and subordinating conjunctions (80%), for a total of another 23% of the test corpus.</S>","<S sid=""81"" ssid=""3"">Other high-frequency word classes with relatively low attachment accuracy are prepositions (80%), adverbs (82%) and subordinating conjunctions (80%), for a total of another 23% of the test corpus.</S>",W06-2932.csv
5,2006,0,0,"The high est score on parsing German in the CoNLL-X shared task was obtained by the system of McDonald et al (2006) with a LAS of 87.34 based on the TIGER tree bank, but we want to stress that these results are not comparable due to different data sets (anda different policy regarding the inclusion of punctuation) .The constituency versions were evaluated according to the labeled recall (LR), labeled precision (LP) and labeled F-score (LF)",W08-1007,Results_Citation,W06-2932,'99',"<S sid=""99"" ssid=""21"">However, if we only look at performance for sentences of length less than 30, the labeled accuracy is still only 71%.</S>","<S sid=""99"" ssid=""21"">However, if we only look at performance for sentences of length less than 30, the labeled accuracy is still only 71%.</S>",W06-2932.csv
6,2006,0,,McDonald et al (2006) use an additional algorithm,W09-1210,Implication_Citation,W06-2932,'89',"<S sid=""89"" ssid=""11"">Another common verb attachment error is a switch between head and dependent verb in phrasal verb forms like dejan intrigar or qiero decir, possibly because the non-finite verb in these cases is often a main verb in training sentences.</S>","<S sid=""89"" ssid=""11"">Another common verb attachment error is a switch between head and dependent verb in phrasal verb forms like dejan intrigar or qiero decir, possibly because the non-finite verb in these cases is often a main verb in training sentences.</S>",W06-2932.csv
7,"McDonald et al, 2006",0,0,"Regarding the data-driven parsers, we have made use of MaltParser (Nivre et al, 2007b) and MST Parser (McDonald et al, 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and tree banks (McDonald and Nivre, 2007)",W12-3407,Implication_Citation,W06-2932,'62',"<S sid=""62"" ssid=""10"">For the remainder of the paper we provide a general error analysis across a wide set of languages plus a detailed error analysis of Spanish and Arabic.</S>","<S sid=""62"" ssid=""10"">For the remainder of the paper we provide a general error analysis across a wide set of languages plus a detailed error analysis of Spanish and Arabic.</S>",W06-2932.csv
8,"McDonald et al, 2006",0,0,"In fact, our approach can also be applied to other parsers, such as (Yamada and Matsumoto, 2003)? s parser, (McDonald et al., 2006)? s parser, and so on",I08-1012,Results_Citation,W06-2932,'77',"<S sid=""77"" ssid=""15"">Similar improvements are common across all languages, though not as dramatic.</S>","<S sid=""77"" ssid=""15"">Similar improvements are common across all languages, though not as dramatic.</S>",W06-2932.csv
11,"McDonald et al, 2006",0,0,"We have shown that, for languages with a7McDonald et al (2006) use post-processing for non projective dependencies and for labeling",N07-1050,Hypothesis_Citation,W06-2932,'93',"<S sid=""93"" ssid=""15"">A quick look at unlabeled attachment accuracies indicate that errors in Arabic parsing are the most common across all languages: prepositions (62%), conjunctions (69%) and to a lesser extent verbs (73%).</S>","<S sid=""93"" ssid=""15"">A quick look at unlabeled attachment accuracies indicate that errors in Arabic parsing are the most common across all languages: prepositions (62%), conjunctions (69%) and to a lesser extent verbs (73%).</S>",W06-2932.csv
12,"McDonald et al, 2006",0,0,"As described in (McDonald et al, 2006), we treat the labeling of dependencies as a sequence labeling problem",D07-1122,Method_Citation,W06-2932,'80',"<S sid=""80"" ssid=""2"">These words form 17% of the test corpus.</S>","<S sid=""80"" ssid=""2"">These words form 17% of the test corpus.</S>",W06-2932.csv
14,2006,0,0,5It should be noted that McDonald et al (2006) use a richer feature set that is incomparable to our features,D07-1015,Method_Citation,W06-2932,'56',"<S sid=""56"" ssid=""4"">Results on the test set are given in Table 1.</S>","<S sid=""56"" ssid=""4"">Results on the test set are given in Table 1.</S>",W06-2932.csv
18,2006,0,0,"Entries marked with? are the highest reported in the literature, to the best of our knowledge, beating (sometimes slightly) McDonald et al (2006), Martins et al (2008), Martins et al (2009), and, in the case of English Proj., also the third-order parser of Koo and Collins (2010), which achieves 93.04% on that dataset (their experiments in Czech are not comparable, since the datasets are different)",D10-1004,Implication_Citation,W06-2932,'65',"<S sid=""65"" ssid=""3"">The benefit of each of these is shown in Table 2.</S>","<S sid=""65"" ssid=""3"">The benefit of each of these is shown in Table 2.</S>",W06-2932.csv
19,"McDonald et al, 2006",0,0,"The specific graph-based model studied in this work is that presented by McDonald et al (2006), which factors scores over pairs of arcs (instead of just single arcs) and uses near exhaustive search for unlabeled parsing coupled with a separate classifier to label each arc. We call this system MSTParser, or simply MST for short, which is also the name of the freely available implementation.2 2.3 Transition-Based Models",P08-1108,Method_Citation,W06-2932,'31',"<S sid=""31"" ssid=""13"">Not all data sets in our experiments include morphological features, so we use them only when available.</S>","<S sid=""31"" ssid=""13"">Not all data sets in our experiments include morphological features, so we use them only when available.</S>",W06-2932.csv
20,"McDonald et al, 2006",0,0,"More precisely, dependency arcs (or pairs of arcs) are first represented by a high dimensional feature vector f (i, j, l)? Rk, where f is typically a bi nary feature vector over properties of the arc as well as the surrounding input (McDonald et al, 2005a; McDonald et al, 2006)",P08-1108,Results_Citation,W06-2932,'61',"<S sid=""61"" ssid=""9"">In fact, for every language our models perform significantly higher than the average performance for all the systems reported in Buchholz et al. (2006).</S>","<S sid=""61"" ssid=""9"">In fact, for every language our models perform significantly higher than the average performance for all the systems reported in Buchholz et al. (2006).</S>",W06-2932.csv
